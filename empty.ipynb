{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
    "                 [[3, 3, 3], [4, 4, 4]],\n",
    "                 [[5, 5, 5], [6, 6, 6]]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.slice(t, [0,0,0], [1,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "for i in range(len(t)):\n",
    "    a = tf.slice(t, [i,0,0], [1,1,3])\n",
    "    lists.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.concat(lists, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.zeros([12, 384, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists=[]\n",
    "for i in range(len(a)):\n",
    "    b = tf.slice(a, [i,0,0], [1, 384, 768])\n",
    "    lists.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat(lists, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.random.uniform([12,384,768],dtype=tf.float32)\n",
    "logits = tf.random.uniform([12,384,1],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.squeeze(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul:0' shape=(12, 384, 768) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.zeros([12,12,114])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.expand_dims(a, 2)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"2[abc]3[cd]ef\"\n",
    "tmp = s.split(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcabccdcdcdef'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = ''\n",
    "for words in tmp:\n",
    "    if '[' in words:\n",
    "        digit, word = words.split('[')\n",
    "        res += int(digit) * word\n",
    "    else:\n",
    "        res += words\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(x1, x2):\n",
    "\n",
    "    x1_rep = x1\n",
    "    x2_rep = x2\n",
    "    x2_rep = tf.transpose(x2_rep, perm=[0, 1, 3, 2])#? * 12 * 768 * 114\n",
    "    scores = tf.einsum('abij,abjk->abik', x1_rep, x2_rep)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = tf.zeros([12,384,768])\n",
    "# history_qa_ids = tf.zeros([12,12,114,768])\n",
    "# history_mask = tf.zeros([12,12,114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_0 = tf.random.uniform([12,384,768],dtype=tf.float32)\n",
    "history_qa_ids = tf.random.uniform([12,12,114,768],dtype=tf.float32)\n",
    "history_mask = tf.random.uniform([12,12,114],dtype=tf.float32)\n",
    "input_tensor = input_tensor_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "x = tf.zeros([12,12,114])\n",
    "x_max = tf.reduce_max(x)\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run(x_max)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 12, 384, 768])"
      ]
     },
     "execution_count": 1194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = tf.expand_dims(input_tensor, 1)\n",
    "input_tensor = tf.tile(input_tensor, [1, history_qa_ids.shape[1], 1, 1])#? * 12 * 384 * 768\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scoring(input_tensor, history_qa_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=False>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_mask = tf.zeros([12,12,114])\n",
    "tmp = tf.cast(history_mask, tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12, 12, 384, 114), dtype=float32, numpy=\n",
       "array([[[[192.30557  , 127.09628  ,  16.344051 , ..., 144.0058   ,\n",
       "           10.827468 ,   7.5531187],\n",
       "         [189.6938   , 118.073296 ,  15.489044 , ..., 134.33255  ,\n",
       "           10.60481  ,   7.188745 ],\n",
       "         [184.3675   , 118.85626  ,  15.437724 , ..., 136.68878  ,\n",
       "           10.476266 ,   7.273374 ],\n",
       "         ...,\n",
       "         [184.89989  , 118.7875   ,  15.358321 , ..., 136.0652   ,\n",
       "           10.380463 ,   7.4600434],\n",
       "         [195.59761  , 123.57488  ,  16.301638 , ..., 141.673    ,\n",
       "           10.763184 ,   7.5090013],\n",
       "         [192.25766  , 118.33291  ,  15.847146 , ..., 136.65858  ,\n",
       "           10.591273 ,   7.3029113]],\n",
       "\n",
       "        [[186.08284  , 121.251785 ,  42.65475  , ..., 200.69844  ,\n",
       "           38.052063 ,  20.294739 ],\n",
       "         [173.74956  , 112.26623  ,  40.44969  , ..., 187.29723  ,\n",
       "           36.06563  ,  19.014906 ],\n",
       "         [173.29851  , 116.26171  ,  40.397606 , ..., 192.17113  ,\n",
       "           36.73207  ,  19.336967 ],\n",
       "         ...,\n",
       "         [180.0697   , 117.33163  ,  40.46005  , ..., 189.26715  ,\n",
       "           36.61688  ,  19.524872 ],\n",
       "         [178.68608  , 119.66809  ,  42.027817 , ..., 193.77335  ,\n",
       "           37.839825 ,  19.894182 ],\n",
       "         [178.24524  , 117.34541  ,  42.05835  , ..., 190.7135   ,\n",
       "           37.25482  ,  19.575087 ]],\n",
       "\n",
       "        [[  5.1542397,  23.262516 , 103.459206 , ..., 139.49774  ,\n",
       "          188.67612  , 138.32497  ],\n",
       "         [  5.0273147,  22.369463 ,  97.231636 , ..., 134.85999  ,\n",
       "          186.1327   , 131.30374  ],\n",
       "         [  4.95284  ,  21.718473 ,  97.50834  , ..., 136.4643   ,\n",
       "          184.65147  , 132.74274  ],\n",
       "         ...,\n",
       "         [  5.136838 ,  22.280138 ,  97.98677  , ..., 136.31302  ,\n",
       "          185.07475  , 134.79863  ],\n",
       "         [  5.17452  ,  22.879654 , 100.608826 , ..., 142.43861  ,\n",
       "          188.36429  , 137.09091  ],\n",
       "         [  5.0741777,  22.418594 ,  99.453384 , ..., 133.45021  ,\n",
       "          183.7184   , 136.18     ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[174.64438  , 119.61357  , 191.72319  , ..., 164.90039  ,\n",
       "          178.871    ,  31.882614 ],\n",
       "         [165.8045   , 114.71644  , 182.0896   , ..., 154.11092  ,\n",
       "          168.26534  ,  32.488213 ],\n",
       "         [166.65665  , 115.34063  , 181.59839  , ..., 157.18475  ,\n",
       "          171.90836  ,  31.252125 ],\n",
       "         ...,\n",
       "         [168.34857  , 114.29137  , 181.35182  , ..., 157.09013  ,\n",
       "          169.62585  ,  31.577555 ],\n",
       "         [176.60443  , 120.11969  , 184.45316  , ..., 164.9187   ,\n",
       "          176.7057   ,  32.966087 ],\n",
       "         [173.63174  , 114.603195 , 180.20303  , ..., 156.3496   ,\n",
       "          170.20193  ,  32.22847  ]],\n",
       "\n",
       "        [[ 18.51481  , 161.32283  ,  68.66059  , ..., 105.802246 ,\n",
       "          117.25723  ,  14.030205 ],\n",
       "         [ 17.997452 , 156.60529  ,  65.05675  , ..., 103.418564 ,\n",
       "          108.53266  ,  13.317734 ],\n",
       "         [ 17.780787 , 156.20758  ,  65.745636 , ..., 100.695724 ,\n",
       "          110.483315 ,  13.445257 ],\n",
       "         ...,\n",
       "         [ 17.68165  , 153.11673  ,  66.518684 , ..., 102.44243  ,\n",
       "          110.68789  ,  13.582828 ],\n",
       "         [ 18.406715 , 159.79991  ,  67.77878  , ..., 107.31943  ,\n",
       "          115.39145  ,  13.742832 ],\n",
       "         [ 18.088537 , 155.55577  ,  66.83294  , ..., 101.32645  ,\n",
       "          113.5986   ,  13.583723 ]],\n",
       "\n",
       "        [[154.42456  ,  63.53866  ,  82.05771  , ..., 112.45938  ,\n",
       "           79.72404  , 192.98964  ],\n",
       "         [147.89177  ,  63.03308  ,  77.55883  , ..., 111.75339  ,\n",
       "           75.65918  , 181.85364  ],\n",
       "         [149.79477  ,  61.520256 ,  76.353966 , ..., 110.30205  ,\n",
       "           74.54555  , 178.93788  ],\n",
       "         ...,\n",
       "         [148.69525  ,  61.39307  ,  76.54959  , ..., 112.06161  ,\n",
       "           75.449425 , 187.42004  ],\n",
       "         [151.10503  ,  64.36484  ,  80.42922  , ..., 114.31192  ,\n",
       "           78.04297  , 191.01416  ],\n",
       "         [149.9233   ,  61.8364   ,  77.93817  , ..., 110.579025 ,\n",
       "           76.598564 , 184.83827  ]]],\n",
       "\n",
       "\n",
       "       [[[165.42657  ,  46.63275  , 125.343155 , ...,  39.733128 ,\n",
       "           58.297688 ,  57.13493  ],\n",
       "         [169.03186  ,  46.364326 , 126.192406 , ...,  40.618126 ,\n",
       "           58.03145  ,  58.11428  ],\n",
       "         [163.80927  ,  46.24473  , 128.10054  , ...,  38.96541  ,\n",
       "           58.29622  ,  57.76565  ],\n",
       "         ...,\n",
       "         [160.07489  ,  45.075848 , 121.30207  , ...,  39.001377 ,\n",
       "           57.182426 ,  55.846718 ],\n",
       "         [175.2252   ,  47.53214  , 132.6336   , ...,  41.74173  ,\n",
       "           60.774197 ,  60.231354 ],\n",
       "         [165.97557  ,  46.69233  , 124.86197  , ...,  40.54161  ,\n",
       "           58.90551  ,  58.694656 ]],\n",
       "\n",
       "        [[115.58701  , 172.01395  , 119.42974  , ..., 160.57928  ,\n",
       "            6.1682596, 122.4436   ],\n",
       "         [118.73222  , 178.38405  , 119.009186 , ..., 159.9101   ,\n",
       "            6.305552 , 126.11552  ],\n",
       "         [115.326126 , 174.41563  , 119.38904  , ..., 160.43248  ,\n",
       "            6.215114 , 126.47756  ],\n",
       "         ...,\n",
       "         [114.59295  , 169.94376  , 115.23069  , ..., 154.43924  ,\n",
       "            6.050711 , 122.397606 ],\n",
       "         [120.46808  , 182.80635  , 124.37768  , ..., 168.40756  ,\n",
       "            6.50112  , 133.47632  ],\n",
       "         [117.90883  , 173.8574   , 118.27616  , ..., 159.45837  ,\n",
       "            6.38099  , 130.07684  ]],\n",
       "\n",
       "        [[ 10.22509  , 144.76581  ,  90.58834  , ..., 172.17302  ,\n",
       "           35.663578 , 162.26451  ],\n",
       "         [ 10.280709 , 150.26085  ,  90.606476 , ..., 172.32199  ,\n",
       "           36.485416 , 165.68576  ],\n",
       "         [ 10.24431  , 144.7254   ,  88.65384  , ..., 172.67334  ,\n",
       "           36.991154 , 164.64578  ],\n",
       "         ...,\n",
       "         [ 10.153459 , 144.01593  ,  86.68186  , ..., 170.7094   ,\n",
       "           34.632977 , 157.5707   ],\n",
       "         [ 10.927009 , 150.20004  ,  91.796135 , ..., 179.21106  ,\n",
       "           36.837498 , 170.90656  ],\n",
       "         [ 10.397833 , 150.51611  ,  91.469124 , ..., 178.54219  ,\n",
       "           36.341343 , 169.77695  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  4.6675396, 112.155014 , 137.51317  , ...,  17.99586  ,\n",
       "           65.39132  ,  62.532673 ],\n",
       "         [  4.5987754, 116.97391  , 136.03273  , ...,  18.344162 ,\n",
       "           66.337494 ,  66.12381  ],\n",
       "         [  4.645075 , 117.05048  , 135.82791  , ...,  18.223234 ,\n",
       "           64.58158  ,  64.46171  ],\n",
       "         ...,\n",
       "         [  4.5444646, 110.03271  , 134.01291  , ...,  17.535782 ,\n",
       "           64.85678  ,  62.789066 ],\n",
       "         [  4.8317575, 121.860794 , 143.30257  , ...,  18.845062 ,\n",
       "           69.75164  ,  67.56659  ],\n",
       "         [  4.7332344, 115.79892  , 137.95372  , ...,  18.501253 ,\n",
       "           67.17742  ,  63.995102 ]],\n",
       "\n",
       "        [[ 97.1237   ,  15.385679 , 154.41539  , ..., 171.9493   ,\n",
       "          157.59877  , 161.90706  ],\n",
       "         [100.147964 ,  16.146671 , 156.45143  , ..., 175.151    ,\n",
       "          157.28969  , 167.75316  ],\n",
       "         [ 98.60288  ,  15.7149105, 155.53177  , ..., 172.62396  ,\n",
       "          156.37134  , 164.8724   ],\n",
       "         ...,\n",
       "         [ 96.05942  ,  15.309875 , 149.32983  , ..., 165.40334  ,\n",
       "          151.68419  , 162.17683  ],\n",
       "         [104.14836  ,  16.66463  , 161.82782  , ..., 173.73125  ,\n",
       "          166.48434  , 174.70963  ],\n",
       "         [ 99.9198   ,  16.00487  , 158.67635  , ..., 169.1222   ,\n",
       "          156.47171  , 168.02379  ]],\n",
       "\n",
       "        [[156.79483  , 140.5433   , 180.0842   , ...,  77.28562  ,\n",
       "          175.76088  ,  64.30349  ],\n",
       "         [155.45058  , 143.8312   , 182.9342   , ...,  78.67594  ,\n",
       "          178.31482  ,  66.06969  ],\n",
       "         [155.30473  , 148.2196   , 180.28807  , ...,  77.29541  ,\n",
       "          181.13913  ,  63.97179  ],\n",
       "         ...,\n",
       "         [150.92227  , 138.17372  , 170.37643  , ...,  73.89452  ,\n",
       "          169.97368  ,  62.459614 ],\n",
       "         [166.81361  , 149.6812   , 189.55307  , ...,  83.7658   ,\n",
       "          187.42105  ,  66.03542  ],\n",
       "         [161.28302  , 144.96869  , 182.71355  , ...,  78.28617  ,\n",
       "          181.30649  ,  63.99693  ]]],\n",
       "\n",
       "\n",
       "       [[[171.71602  ,  30.505566 , 148.30432  , ...,  74.62755  ,\n",
       "           14.382155 , 106.163956 ],\n",
       "         [166.9084   ,  29.037926 , 151.03667  , ...,  73.86155  ,\n",
       "           14.313431 , 102.57534  ],\n",
       "         [162.80511  ,  29.092003 , 145.07596  , ...,  73.676445 ,\n",
       "           14.233014 , 102.54533  ],\n",
       "         ...,\n",
       "         [167.06471  ,  28.911325 , 146.71225  , ...,  74.0414   ,\n",
       "           14.59977  , 100.69922  ],\n",
       "         [164.6998   ,  28.68429  , 144.58894  , ...,  72.17331  ,\n",
       "           13.745844 ,  99.20418  ],\n",
       "         [167.0895   ,  28.747046 , 141.7886   , ...,  71.7173   ,\n",
       "           13.553198 , 100.28592  ]],\n",
       "\n",
       "        [[149.0578   , 123.09869  , 184.38254  , ...,   9.690931 ,\n",
       "            5.468483 ,  94.40466  ],\n",
       "         [145.5372   , 120.27865  , 181.18256  , ...,   9.64152  ,\n",
       "            5.4373913,  91.64424  ],\n",
       "         [137.03545  , 118.86187  , 177.11626  , ...,   9.306096 ,\n",
       "            5.352486 ,  90.360504 ],\n",
       "         ...,\n",
       "         [144.68793  , 121.53604  , 176.64497  , ...,   9.318269 ,\n",
       "            5.2551956,  94.83422  ],\n",
       "         [138.09854  , 117.13064  , 179.38968  , ...,   9.2882395,\n",
       "            5.245115 ,  90.38656  ],\n",
       "         [136.09395  , 116.970055 , 171.06519  , ...,   9.3393345,\n",
       "            5.213333 ,  90.552734 ]],\n",
       "\n",
       "        [[ 20.86621  ,  61.439613 , 147.00208  , ..., 169.8691   ,\n",
       "           70.3319   ,  33.70029  ],\n",
       "         [ 21.16007  ,  60.72778  , 148.90646  , ..., 170.13052  ,\n",
       "           67.40427  ,  33.494465 ],\n",
       "         [ 20.572083 ,  59.366703 , 143.463    , ..., 163.17589  ,\n",
       "           67.56345  ,  32.312572 ],\n",
       "         ...,\n",
       "         [ 20.855495 ,  60.074802 , 145.70807  , ..., 172.18347  ,\n",
       "           68.45513  ,  33.414547 ],\n",
       "         [ 20.557018 ,  58.687527 , 143.97174  , ..., 161.3393   ,\n",
       "           67.26791  ,  32.92066  ],\n",
       "         [ 20.278145 ,  58.749783 , 142.44539  , ..., 164.25362  ,\n",
       "           64.61668  ,  32.35419  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 53.49336  ,  37.70736  , 179.48366  , ..., 177.27756  ,\n",
       "          109.32441  ,  38.71437  ],\n",
       "         [ 52.27959  ,  36.372284 , 179.31941  , ..., 171.97862  ,\n",
       "          108.94818  ,  38.126896 ],\n",
       "         [ 52.88588  ,  34.932426 , 173.9614   , ..., 166.48251  ,\n",
       "          103.92158  ,  35.31178  ],\n",
       "         ...,\n",
       "         [ 52.302204 ,  35.74174  , 173.3551   , ..., 174.39134  ,\n",
       "          105.14165  ,  37.559746 ],\n",
       "         [ 52.00433  ,  35.41653  , 174.24525  , ..., 172.88164  ,\n",
       "          107.222534 ,  37.176453 ],\n",
       "         [ 51.409863 ,  35.088818 , 172.25902  , ..., 168.10661  ,\n",
       "          104.359695 ,  35.92009  ]],\n",
       "\n",
       "        [[168.59834  , 195.15846  ,  35.36973  , ...,  18.68456  ,\n",
       "          135.52559  ,  67.64996  ],\n",
       "         [165.50586  , 189.4315   ,  35.117867 , ...,  18.696314 ,\n",
       "          132.96193  ,  65.6282   ],\n",
       "         [158.03427  , 184.90051  ,  33.689613 , ...,  18.57594  ,\n",
       "          130.19481  ,  63.069927 ],\n",
       "         ...,\n",
       "         [159.2556   , 187.3549   ,  35.32999  , ...,  18.663279 ,\n",
       "          131.61868  ,  65.80023  ],\n",
       "         [160.17397  , 183.95053  ,  33.709087 , ...,  18.491032 ,\n",
       "          129.22011  ,  65.00058  ],\n",
       "         [155.0193   , 180.43527  ,  35.01506  , ...,  18.274712 ,\n",
       "          129.10132  ,  63.396194 ]],\n",
       "\n",
       "        [[ 65.30173  ,  93.70893  , 115.304214 , ..., 101.56077  ,\n",
       "           97.11905  ,  77.900154 ],\n",
       "         [ 65.38072  ,  92.20685  , 112.659515 , ...,  99.20166  ,\n",
       "           92.18872  ,  76.82843  ],\n",
       "         [ 63.01178  ,  90.86829  , 112.88734  , ...,  97.74185  ,\n",
       "           92.45406  ,  75.68177  ],\n",
       "         ...,\n",
       "         [ 65.00117  ,  92.883545 , 115.078    , ...,  99.433495 ,\n",
       "           94.05004  ,  77.221596 ],\n",
       "         [ 62.60252  ,  90.75604  , 109.9653   , ...,  97.25164  ,\n",
       "           91.3414   ,  74.80317  ],\n",
       "         [ 62.100445 ,  91.192894 , 108.60425  , ...,  97.88328  ,\n",
       "           92.38387  ,  73.394165 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[143.56227  ,   4.807563 , 181.44185  , ...,  26.831482 ,\n",
       "           96.566414 , 151.99736  ],\n",
       "         [143.75867  ,   4.6831965, 175.47887  , ...,  26.0936   ,\n",
       "           96.28608  , 149.65797  ],\n",
       "         [136.5819   ,   4.6350937, 174.16234  , ...,  25.896656 ,\n",
       "           92.14174  , 145.6514   ],\n",
       "         ...,\n",
       "         [139.15646  ,   4.771379 , 171.27684  , ...,  26.130873 ,\n",
       "           95.632545 , 150.54384  ],\n",
       "         [142.33278  ,   4.8094726, 178.73749  , ...,  27.588636 ,\n",
       "           96.8911   , 155.57541  ],\n",
       "         [141.9099   ,   4.777082 , 181.36903  , ...,  26.2636   ,\n",
       "           99.004364 , 153.10658  ]],\n",
       "\n",
       "        [[158.30672  , 115.62686  , 190.83263  , ..., 138.5124   ,\n",
       "           41.624874 ,  74.223404 ],\n",
       "         [157.61182  , 113.3368   , 191.28268  , ..., 136.75021  ,\n",
       "           40.08505  ,  72.74605  ],\n",
       "         [153.7877   , 112.17098  , 180.42125  , ..., 134.12328  ,\n",
       "           40.422405 ,  70.204185 ],\n",
       "         ...,\n",
       "         [152.99297  , 110.219894 , 188.24011  , ..., 136.39479  ,\n",
       "           41.1154   ,  70.08292  ],\n",
       "         [157.70595  , 115.17165  , 183.03017  , ..., 137.09909  ,\n",
       "           40.328136 ,  72.67512  ],\n",
       "         [156.83098  , 114.14241  , 189.14175  , ..., 134.69923  ,\n",
       "           40.861145 ,  72.67245  ]],\n",
       "\n",
       "        [[ 87.41036  ,  21.728022 , 140.18756  , ..., 178.29573  ,\n",
       "          156.53421  ,  48.672363 ],\n",
       "         [ 86.55568  ,  21.172401 , 136.81624  , ..., 173.36418  ,\n",
       "          154.00792  ,  46.328594 ],\n",
       "         [ 83.82429  ,  20.876612 , 132.49748  , ..., 171.65837  ,\n",
       "          151.4153   ,  45.84832  ],\n",
       "         ...,\n",
       "         [ 87.38261  ,  20.015722 , 136.08002  , ..., 167.9561   ,\n",
       "          152.71758  ,  47.238255 ],\n",
       "         [ 89.25628  ,  21.270447 , 138.9082   , ..., 175.6386   ,\n",
       "          158.22157  ,  47.87958  ],\n",
       "         [ 88.89679  ,  21.189972 , 135.69434  , ..., 174.33887  ,\n",
       "          156.229    ,  47.31666  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 68.697075 , 113.8272   ,  89.276764 , ...,  83.62948  ,\n",
       "          148.61108  ,  87.46162  ],\n",
       "         [ 66.13858  , 113.751785 ,  89.173485 , ...,  81.80331  ,\n",
       "          141.04424  ,  86.80806  ],\n",
       "         [ 65.15687  , 109.76384  ,  85.443756 , ...,  80.92006  ,\n",
       "          138.78831  ,  83.59627  ],\n",
       "         ...,\n",
       "         [ 66.91896  , 111.06819  ,  86.62282  , ...,  82.48089  ,\n",
       "          139.46767  ,  86.98085  ],\n",
       "         [ 68.64337  , 113.27197  ,  88.85231  , ...,  83.51706  ,\n",
       "          145.21135  ,  87.355515 ],\n",
       "         [ 68.59389  , 113.08938  ,  86.40493  , ...,  82.56317  ,\n",
       "          143.01462  ,  86.87113  ]],\n",
       "\n",
       "        [[125.69499  , 190.00774  ,  80.84874  , ...,  90.93462  ,\n",
       "           22.621078 , 157.97878  ],\n",
       "         [119.001595 , 184.24637  ,  78.12159  , ...,  87.962105 ,\n",
       "           22.082039 , 155.70222  ],\n",
       "         [117.22216  , 182.59077  ,  77.012535 , ...,  87.956924 ,\n",
       "           21.795698 , 150.77728  ],\n",
       "         ...,\n",
       "         [118.91167  , 186.5641   ,  77.25174  , ...,  87.02611  ,\n",
       "           22.13572  , 153.55771  ],\n",
       "         [120.110535 , 189.72868  ,  80.16418  , ...,  89.657684 ,\n",
       "           23.020853 , 155.39317  ],\n",
       "         [119.357704 , 186.12018  ,  79.05389  , ...,  87.32655  ,\n",
       "           22.544117 , 154.3388   ]],\n",
       "\n",
       "        [[ 66.31747  , 149.84077  , 188.8092   , ..., 190.49916  ,\n",
       "           13.271165 , 126.89464  ],\n",
       "         [ 63.64048  , 143.46643  , 183.25308  , ..., 188.74423  ,\n",
       "           12.779307 , 124.70984  ],\n",
       "         [ 62.095657 , 139.53673  , 184.85963  , ..., 183.91603  ,\n",
       "           12.624233 , 119.44431  ],\n",
       "         ...,\n",
       "         [ 62.869404 , 141.45505  , 186.0832   , ..., 183.76318  ,\n",
       "           12.750129 , 124.33237  ],\n",
       "         [ 64.049675 , 148.16757  , 192.25742  , ..., 191.5114   ,\n",
       "           12.79025  , 125.91047  ],\n",
       "         [ 62.610268 , 147.45088  , 188.0642   , ..., 186.96341  ,\n",
       "           13.003885 , 122.59214  ]]],\n",
       "\n",
       "\n",
       "       [[[ 82.84141  , 118.06996  ,  84.29664  , ...,  52.019222 ,\n",
       "          167.96559  , 169.971    ],\n",
       "         [ 85.609764 , 118.01743  ,  85.28205  , ...,  53.982536 ,\n",
       "          170.74722  , 175.3496   ],\n",
       "         [ 87.68686  , 120.95673  ,  87.59767  , ...,  54.447712 ,\n",
       "          170.97665  , 182.40218  ],\n",
       "         ...,\n",
       "         [ 82.32876  , 117.62084  ,  81.40013  , ...,  53.451035 ,\n",
       "          164.64496  , 170.02922  ],\n",
       "         [ 86.67013  , 120.8885   ,  89.570496 , ...,  54.83359  ,\n",
       "          173.14621  , 179.20071  ],\n",
       "         [ 83.2062   , 114.339676 ,  84.628555 , ...,  52.448765 ,\n",
       "          168.51039  , 171.86774  ]],\n",
       "\n",
       "        [[182.10469  ,  12.742393 , 183.6243   , ...,  41.50365  ,\n",
       "           99.25723  ,  51.847942 ],\n",
       "         [188.98804  ,  13.03261  , 181.05789  , ...,  42.563725 ,\n",
       "          103.05944  ,  55.14378  ],\n",
       "         [191.92194  ,  13.310334 , 184.2078   , ...,  43.98363  ,\n",
       "          104.636826 ,  55.653202 ],\n",
       "         ...,\n",
       "         [183.13103  ,  12.659371 , 179.31447  , ...,  42.513557 ,\n",
       "           98.50414  ,  53.75432  ],\n",
       "         [188.96573  ,  13.273029 , 186.56114  , ...,  43.84059  ,\n",
       "          104.95656  ,  54.15152  ],\n",
       "         [185.66039  ,  12.720171 , 181.8556   , ...,  43.009895 ,\n",
       "          101.14993  ,  53.330387 ]],\n",
       "\n",
       "        [[ 59.822723 , 126.66145  ,  74.44833  , ..., 147.92517  ,\n",
       "           13.254761 ,  93.461494 ],\n",
       "         [ 62.207726 , 128.84131  ,  76.88367  , ..., 154.70007  ,\n",
       "           13.846005 ,  96.49777  ],\n",
       "         [ 61.76666  , 126.64997  ,  76.48229  , ..., 154.46413  ,\n",
       "           13.631919 ,  99.64189  ],\n",
       "         ...,\n",
       "         [ 60.850304 , 123.70247  ,  72.555016 , ..., 149.60008  ,\n",
       "           13.2937565,  94.605484 ],\n",
       "         [ 61.879803 , 127.87889  ,  77.90926  , ..., 158.55879  ,\n",
       "           13.632351 ,  98.10841  ],\n",
       "         [ 60.49986  , 127.72331  ,  76.288605 , ..., 150.50143  ,\n",
       "           13.614357 ,  94.81998  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 98.75311  ,  24.299025 , 122.82727  , ...,  83.290924 ,\n",
       "          138.27754  , 180.50761  ],\n",
       "         [103.0098   ,  26.084518 , 126.46044  , ...,  83.97024  ,\n",
       "          144.2261   , 190.11807  ],\n",
       "         [104.846085 ,  25.578325 , 129.85141  , ...,  86.550674 ,\n",
       "          145.37581  , 190.47963  ],\n",
       "         ...,\n",
       "         [ 98.955925 ,  24.65276  , 126.83784  , ...,  83.147896 ,\n",
       "          140.04976  , 181.22534  ],\n",
       "         [104.40813  ,  26.236374 , 130.04881  , ...,  86.34359  ,\n",
       "          147.49721  , 187.48279  ],\n",
       "         [100.47743  ,  24.454212 , 127.83064  , ...,  82.94054  ,\n",
       "          144.16425  , 181.1292   ]],\n",
       "\n",
       "        [[157.92409  , 165.49869  ,  99.81069  , ...,  68.57356  ,\n",
       "          140.81238  , 154.783    ],\n",
       "         [165.20685  , 169.09024  , 105.88228  , ...,  71.60522  ,\n",
       "          144.36043  , 152.3461   ],\n",
       "         [168.20056  , 173.10387  , 106.31779  , ...,  72.59151  ,\n",
       "          144.91438  , 159.47583  ],\n",
       "         ...,\n",
       "         [161.69037  , 166.12018  , 101.91469  , ...,  69.187454 ,\n",
       "          135.71567  , 155.1489   ],\n",
       "         [167.7108   , 176.19426  , 107.123505 , ...,  73.518974 ,\n",
       "          145.84639  , 159.51176  ],\n",
       "         [159.01196  , 165.3916   , 101.79104  , ...,  68.6542   ,\n",
       "          140.97182  , 153.04799  ]],\n",
       "\n",
       "        [[105.12578  ,  87.97451  , 135.86673  , ..., 150.14299  ,\n",
       "           21.812843 ,  36.37458  ],\n",
       "         [111.61867  ,  90.30766  , 139.71568  , ..., 153.22247  ,\n",
       "           21.86621  ,  37.58797  ],\n",
       "         [112.16097  ,  91.000824 , 139.41382  , ..., 153.37054  ,\n",
       "           22.75391  ,  38.36083  ],\n",
       "         ...,\n",
       "         [106.978676 ,  88.48994  , 134.93962  , ..., 147.67276  ,\n",
       "           21.907763 ,  36.199112 ],\n",
       "         [112.615005 ,  93.86924  , 143.07878  , ..., 155.24956  ,\n",
       "           22.492702 ,  37.894775 ],\n",
       "         [108.02665  ,  86.8257   , 136.8212   , ..., 146.53021  ,\n",
       "           22.050598 ,  37.026276 ]]],\n",
       "\n",
       "\n",
       "       [[[160.588    , 168.66174  ,  17.762476 , ...,  10.7545   ,\n",
       "           71.04474  , 106.7218   ],\n",
       "         [171.5439   , 182.14078  ,  19.298937 , ...,  11.740504 ,\n",
       "           75.796196 , 115.121635 ],\n",
       "         [166.87791  , 175.42226  ,  18.421429 , ...,  11.393229 ,\n",
       "           73.461624 , 110.43142  ],\n",
       "         ...,\n",
       "         [170.80475  , 182.88857  ,  19.04539  , ...,  11.4272   ,\n",
       "           72.50405  , 113.93764  ],\n",
       "         [164.18907  , 168.48064  ,  18.359852 , ...,  10.771366 ,\n",
       "           71.75713  , 106.8939   ],\n",
       "         [169.51518  , 173.48831  ,  18.39181  , ...,  10.751597 ,\n",
       "           72.33873  , 107.568184 ]],\n",
       "\n",
       "        [[ 79.05547  , 158.61661  ,  47.810276 , ..., 107.598305 ,\n",
       "           60.61784  ,  40.702484 ],\n",
       "         [ 83.596    , 169.73619  ,  50.5589   , ..., 113.39723  ,\n",
       "           64.807076 ,  44.13277  ],\n",
       "         [ 82.26129  , 164.34325  ,  47.968506 , ..., 109.160965 ,\n",
       "           62.289062 ,  41.361263 ],\n",
       "         ...,\n",
       "         [ 81.682076 , 170.23645  ,  49.295746 , ..., 112.5928   ,\n",
       "           63.22474  ,  42.237793 ],\n",
       "         [ 79.99303  , 161.851    ,  48.17078  , ..., 108.566696 ,\n",
       "           60.959282 ,  41.31385  ],\n",
       "         [ 80.056465 , 164.58401  ,  48.19362  , ..., 108.67639  ,\n",
       "           62.50583  ,  41.408867 ]],\n",
       "\n",
       "        [[150.81305  , 153.31357  , 135.9569   , ...,  44.88362  ,\n",
       "           59.80599  ,  24.143702 ],\n",
       "         [161.17165  , 159.21407  , 143.85982  , ...,  48.132664 ,\n",
       "           62.402294 ,  25.619007 ],\n",
       "         [153.85316  , 155.71909  , 139.44467  , ...,  45.53264  ,\n",
       "           61.15697  ,  24.799896 ],\n",
       "         ...,\n",
       "         [157.59854  , 159.15977  , 141.99425  , ...,  47.42131  ,\n",
       "           62.443855 ,  25.467781 ],\n",
       "         [150.34866  , 154.79376  , 133.01175  , ...,  45.4223   ,\n",
       "           58.972214 ,  24.525671 ],\n",
       "         [149.35938  , 154.94612  , 136.49475  , ...,  46.35967  ,\n",
       "           60.053303 ,  24.608202 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[106.325325 ,   2.0026364,  83.18251  , ..., 184.25221  ,\n",
       "          112.83913  , 102.381454 ],\n",
       "         [113.49426  ,   2.0873704,  87.49875  , ..., 198.04523  ,\n",
       "          121.482735 , 107.95336  ],\n",
       "         [110.36262  ,   2.0896773,  83.76402  , ..., 192.24829  ,\n",
       "          116.19608  , 104.56986  ],\n",
       "         ...,\n",
       "         [112.29304  ,   2.0856373,  86.08983  , ..., 195.11572  ,\n",
       "          119.2422   , 106.69609  ],\n",
       "         [109.93058  ,   2.030323 ,  83.19339  , ..., 187.21434  ,\n",
       "          113.49062  , 102.37123  ],\n",
       "         [112.043144 ,   2.0397313,  84.65065  , ..., 190.44489  ,\n",
       "          114.64762  , 104.20561  ]],\n",
       "\n",
       "        [[143.6618   , 177.71048  , 189.59161  , ..., 118.94339  ,\n",
       "           67.686874 , 138.83116  ],\n",
       "         [156.68044  , 187.36507  , 198.34373  , ..., 129.4168   ,\n",
       "           73.23847  , 144.56686  ],\n",
       "         [154.95816  , 179.91452  , 191.8528   , ..., 126.11988  ,\n",
       "           71.05553  , 143.05568  ],\n",
       "         ...,\n",
       "         [156.37521  , 186.42586  , 193.2988   , ..., 126.18416  ,\n",
       "           72.87982  , 141.74191  ],\n",
       "         [147.31517  , 174.7716   , 189.24838  , ..., 121.23774  ,\n",
       "           70.30706  , 136.7472   ],\n",
       "         [150.14572  , 176.7999   , 190.10713  , ..., 123.81316  ,\n",
       "           72.10913  , 141.74     ]],\n",
       "\n",
       "        [[ 75.49603  , 109.17427  , 187.85991  , ..., 105.68517  ,\n",
       "           43.335083 , 187.14314  ],\n",
       "         [ 80.748604 , 117.30518  , 197.51581  , ..., 115.711494 ,\n",
       "           48.569294 , 202.06502  ],\n",
       "         [ 77.761475 , 111.65337  , 187.53806  , ..., 110.17354  ,\n",
       "           45.73692  , 192.98268  ],\n",
       "         ...,\n",
       "         [ 78.062996 , 116.644135 , 195.77783  , ..., 114.99471  ,\n",
       "           47.281223 , 196.14328  ],\n",
       "         [ 77.200905 , 109.9792   , 183.56648  , ..., 107.387405 ,\n",
       "           45.960014 , 188.06721  ],\n",
       "         [ 75.52649  , 114.29605  , 192.6094   , ..., 107.56878  ,\n",
       "           46.012745 , 192.39111  ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 1196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history_mask = tf.cast(history_mask,tf.bool)==False\n",
    "history_mask = tf.expand_dims(history_mask, 2)\n",
    "empty_mask = tf.tile(history_mask, [1, 1, scores.shape[2], 1])#矩阵扩张\n",
    "score = tf.cast(scores, tf.float32)\n",
    "empty_mask = tf.cast(empty_mask, tf.float32)\n",
    "negmask = 1 - empty_mask\n",
    "num = 3.4 * math.pow(10, 38)\n",
    "score =  (score * empty_mask)\n",
    "# + (-((negmask * num + num) - num))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 12, 384, 114])"
      ]
     },
     "execution_count": 1197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12, 4608, 114), dtype=float32, numpy=\n",
       "array([[[192.30557  , 127.09628  ,  16.344051 , ..., 144.0058   ,\n",
       "          10.827468 ,   7.5531187],\n",
       "        [189.6938   , 118.073296 ,  15.489044 , ..., 134.33255  ,\n",
       "          10.60481  ,   7.188745 ],\n",
       "        [184.3675   , 118.85626  ,  15.437724 , ..., 136.68878  ,\n",
       "          10.476266 ,   7.273374 ],\n",
       "        ...,\n",
       "        [148.69525  ,  61.39307  ,  76.54959  , ..., 112.06161  ,\n",
       "          75.449425 , 187.42004  ],\n",
       "        [151.10503  ,  64.36484  ,  80.42922  , ..., 114.31192  ,\n",
       "          78.04297  , 191.01416  ],\n",
       "        [149.9233   ,  61.8364   ,  77.93817  , ..., 110.579025 ,\n",
       "          76.598564 , 184.83827  ]],\n",
       "\n",
       "       [[165.42657  ,  46.63275  , 125.343155 , ...,  39.733128 ,\n",
       "          58.297688 ,  57.13493  ],\n",
       "        [169.03186  ,  46.364326 , 126.192406 , ...,  40.618126 ,\n",
       "          58.03145  ,  58.11428  ],\n",
       "        [163.80927  ,  46.24473  , 128.10054  , ...,  38.96541  ,\n",
       "          58.29622  ,  57.76565  ],\n",
       "        ...,\n",
       "        [150.92227  , 138.17372  , 170.37643  , ...,  73.89452  ,\n",
       "         169.97368  ,  62.459614 ],\n",
       "        [166.81361  , 149.6812   , 189.55307  , ...,  83.7658   ,\n",
       "         187.42105  ,  66.03542  ],\n",
       "        [161.28302  , 144.96869  , 182.71355  , ...,  78.28617  ,\n",
       "         181.30649  ,  63.99693  ]],\n",
       "\n",
       "       [[171.71602  ,  30.505566 , 148.30432  , ...,  74.62755  ,\n",
       "          14.382155 , 106.163956 ],\n",
       "        [166.9084   ,  29.037926 , 151.03667  , ...,  73.86155  ,\n",
       "          14.313431 , 102.57534  ],\n",
       "        [162.80511  ,  29.092003 , 145.07596  , ...,  73.676445 ,\n",
       "          14.233014 , 102.54533  ],\n",
       "        ...,\n",
       "        [ 65.00117  ,  92.883545 , 115.078    , ...,  99.433495 ,\n",
       "          94.05004  ,  77.221596 ],\n",
       "        [ 62.60252  ,  90.75604  , 109.9653   , ...,  97.25164  ,\n",
       "          91.3414   ,  74.80317  ],\n",
       "        [ 62.100445 ,  91.192894 , 108.60425  , ...,  97.88328  ,\n",
       "          92.38387  ,  73.394165 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[143.56227  ,   4.807563 , 181.44185  , ...,  26.831482 ,\n",
       "          96.566414 , 151.99736  ],\n",
       "        [143.75867  ,   4.6831965, 175.47887  , ...,  26.0936   ,\n",
       "          96.28608  , 149.65797  ],\n",
       "        [136.5819   ,   4.6350937, 174.16234  , ...,  25.896656 ,\n",
       "          92.14174  , 145.6514   ],\n",
       "        ...,\n",
       "        [ 62.869404 , 141.45505  , 186.0832   , ..., 183.76318  ,\n",
       "          12.750129 , 124.33237  ],\n",
       "        [ 64.049675 , 148.16757  , 192.25742  , ..., 191.5114   ,\n",
       "          12.79025  , 125.91047  ],\n",
       "        [ 62.610268 , 147.45088  , 188.0642   , ..., 186.96341  ,\n",
       "          13.003885 , 122.59214  ]],\n",
       "\n",
       "       [[ 82.84141  , 118.06996  ,  84.29664  , ...,  52.019222 ,\n",
       "         167.96559  , 169.971    ],\n",
       "        [ 85.609764 , 118.01743  ,  85.28205  , ...,  53.982536 ,\n",
       "         170.74722  , 175.3496   ],\n",
       "        [ 87.68686  , 120.95673  ,  87.59767  , ...,  54.447712 ,\n",
       "         170.97665  , 182.40218  ],\n",
       "        ...,\n",
       "        [106.978676 ,  88.48994  , 134.93962  , ..., 147.67276  ,\n",
       "          21.907763 ,  36.199112 ],\n",
       "        [112.615005 ,  93.86924  , 143.07878  , ..., 155.24956  ,\n",
       "          22.492702 ,  37.894775 ],\n",
       "        [108.02665  ,  86.8257   , 136.8212   , ..., 146.53021  ,\n",
       "          22.050598 ,  37.026276 ]],\n",
       "\n",
       "       [[160.588    , 168.66174  ,  17.762476 , ...,  10.7545   ,\n",
       "          71.04474  , 106.7218   ],\n",
       "        [171.5439   , 182.14078  ,  19.298937 , ...,  11.740504 ,\n",
       "          75.796196 , 115.121635 ],\n",
       "        [166.87791  , 175.42226  ,  18.421429 , ...,  11.393229 ,\n",
       "          73.461624 , 110.43142  ],\n",
       "        ...,\n",
       "        [ 78.062996 , 116.644135 , 195.77783  , ..., 114.99471  ,\n",
       "          47.281223 , 196.14328  ],\n",
       "        [ 77.200905 , 109.9792   , 183.56648  , ..., 107.387405 ,\n",
       "          45.960014 , 188.06721  ],\n",
       "        [ 75.52649  , 114.29605  , 192.6094   , ..., 107.56878  ,\n",
       "          46.012745 , 192.39111  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 1198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = tf.unstack(score, axis=1)\n",
    "n = len(score)\n",
    "score = tf.concat([i for i in score], 1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha_flat = tf.nn.softmax(score, axis=2)\n",
    "alpha_flat = tf.split(alpha_flat, n, axis=1)\n",
    "# alpha_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([12, 12, 384, 114]), TensorShape([12, 12, 384, 114]))"
      ]
     },
     "execution_count": 1181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "alpha = tf.stack([i for i in alpha_flat], axis=1)\n",
    "alpha.shape, alpha.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12, 12, 384, 768), dtype=float32, numpy=\n",
       "array([[[[0.8410448 , 0.13830543, 0.00114262, ..., 0.52358794,\n",
       "          0.72532535, 0.971872  ],\n",
       "         [0.8410448 , 0.13830543, 0.00114262, ..., 0.52358794,\n",
       "          0.72532535, 0.971872  ],\n",
       "         [0.8410448 , 0.13830543, 0.00114262, ..., 0.52358794,\n",
       "          0.72532535, 0.971872  ],\n",
       "         ...,\n",
       "         [0.8410448 , 0.13830543, 0.00114262, ..., 0.52358794,\n",
       "          0.72532535, 0.971872  ],\n",
       "         [0.8410448 , 0.13830543, 0.00114262, ..., 0.52358794,\n",
       "          0.72532535, 0.971872  ],\n",
       "         [0.8410448 , 0.13830543, 0.00114262, ..., 0.52358794,\n",
       "          0.72532535, 0.971872  ]],\n",
       "\n",
       "        [[0.94210297, 0.41609344, 0.9002107 , ..., 0.05773615,\n",
       "          0.46965045, 0.34663984],\n",
       "         [0.94384927, 0.41795754, 0.90637714, ..., 0.05107086,\n",
       "          0.47022146, 0.35164154],\n",
       "         [0.8458577 , 0.4704825 , 0.8786709 , ..., 0.04699301,\n",
       "          0.44729236, 0.3265707 ],\n",
       "         ...,\n",
       "         [0.9492508 , 0.42051902, 0.91398126, ..., 0.03870113,\n",
       "          0.47390854, 0.3517482 ],\n",
       "         [0.7880625 , 0.4614253 , 0.80718505, ..., 0.13813044,\n",
       "          0.42045882, 0.29960743],\n",
       "         [0.8926367 , 0.4497224 , 0.89661944, ..., 0.03899134,\n",
       "          0.46018875, 0.337363  ]],\n",
       "\n",
       "        [[0.4228679 , 0.03443841, 0.5151507 , ..., 0.4862464 ,\n",
       "          0.52438295, 0.64635295],\n",
       "         [0.42286777, 0.03443825, 0.51515067, ..., 0.48624635,\n",
       "          0.52438295, 0.646353  ],\n",
       "         [0.422868  , 0.03443864, 0.51515067, ..., 0.48624644,\n",
       "          0.5243828 , 0.64635277],\n",
       "         ...,\n",
       "         [0.42286795, 0.03443856, 0.51515067, ..., 0.48624644,\n",
       "          0.5243828 , 0.6463528 ],\n",
       "         [0.42286813, 0.03443883, 0.51515067, ..., 0.4862465 ,\n",
       "          0.52438277, 0.64635265],\n",
       "         [0.42286777, 0.03443826, 0.51515067, ..., 0.48624635,\n",
       "          0.52438295, 0.646353  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4466566 , 0.14072195, 0.10194222, ..., 0.57196736,\n",
       "          0.14772724, 0.45124847],\n",
       "         [0.45000017, 0.15289164, 0.11990689, ..., 0.56067544,\n",
       "          0.1621511 , 0.46348268],\n",
       "         [0.4503192 , 0.15404585, 0.12160125, ..., 0.5596194 ,\n",
       "          0.1635243 , 0.46463475],\n",
       "         ...,\n",
       "         [0.44628283, 0.14011888, 0.10119594, ..., 0.5722942 ,\n",
       "          0.1471272 , 0.45090947],\n",
       "         [0.4462392 , 0.13989384, 0.10085119, ..., 0.57252324,\n",
       "          0.14685042, 0.45065987],\n",
       "         [0.4480663 , 0.14355053, 0.10568178, ..., 0.570048  ,\n",
       "          0.15073018, 0.45328096]],\n",
       "\n",
       "        [[0.6992061 , 0.6592998 , 0.6948801 , ..., 0.89192384,\n",
       "          0.8119706 , 0.60542387],\n",
       "         [0.69920766, 0.65927386, 0.69484746, ..., 0.8918835 ,\n",
       "          0.81194574, 0.60539865],\n",
       "         [0.69922256, 0.6592701 , 0.6948483 , ..., 0.89189386,\n",
       "          0.81193995, 0.60541046],\n",
       "         ...,\n",
       "         [0.69919395, 0.6592549 , 0.6948181 , ..., 0.8918378 ,\n",
       "          0.81193   , 0.60536444],\n",
       "         [0.69916654, 0.6589554 , 0.6944252 , ..., 0.8913237 ,\n",
       "          0.81165123, 0.6050252 ],\n",
       "         [0.69936866, 0.6589352 , 0.69447464, ..., 0.8915122 ,\n",
       "          0.81160045, 0.60521746]],\n",
       "\n",
       "        [[0.48027706, 0.21606624, 0.9565257 , ..., 0.05012441,\n",
       "          0.12154853, 0.5536221 ],\n",
       "         [0.48027706, 0.21606624, 0.9565257 , ..., 0.05012441,\n",
       "          0.12154854, 0.5536221 ],\n",
       "         [0.48027706, 0.21606624, 0.9565257 , ..., 0.05012441,\n",
       "          0.12154853, 0.5536221 ],\n",
       "         ...,\n",
       "         [0.48027706, 0.21606624, 0.9565257 , ..., 0.05012441,\n",
       "          0.12154853, 0.5536221 ],\n",
       "         [0.48027706, 0.21606624, 0.9565257 , ..., 0.05012441,\n",
       "          0.12154853, 0.5536221 ],\n",
       "         [0.48027706, 0.21606624, 0.9565257 , ..., 0.05012441,\n",
       "          0.12154853, 0.5536221 ]]],\n",
       "\n",
       "\n",
       "       [[[0.761765  , 0.21844587, 0.16971919, ..., 0.9493936 ,\n",
       "          0.29802018, 0.48336446],\n",
       "         [0.761784  , 0.21843581, 0.16971834, ..., 0.94940627,\n",
       "          0.29800895, 0.48335218],\n",
       "         [0.76178384, 0.21843591, 0.16971835, ..., 0.94940615,\n",
       "          0.29800907, 0.48335233],\n",
       "         ...,\n",
       "         [0.7591986 , 0.21980578, 0.16983372, ..., 0.94768035,\n",
       "          0.29953817, 0.48502225],\n",
       "         [0.7617828 , 0.21843645, 0.1697184 , ..., 0.9494055 ,\n",
       "          0.29800966, 0.48335296],\n",
       "         [0.76164824, 0.21850769, 0.16972439, ..., 0.9493156 ,\n",
       "          0.29808918, 0.4834398 ]],\n",
       "\n",
       "        [[0.33316597, 0.49674633, 0.14284301, ..., 0.43661153,\n",
       "          0.863995  , 0.12815592],\n",
       "         [0.9265953 , 0.28842235, 0.02144691, ..., 0.24166574,\n",
       "          0.3321945 , 0.11420589],\n",
       "         [0.2506528 , 0.52571267, 0.15972248, ..., 0.46371773,\n",
       "          0.93793905, 0.13009559],\n",
       "         ...,\n",
       "         [0.27157408, 0.5183682 , 0.15544266, ..., 0.4568449 ,\n",
       "          0.91919035, 0.12960377],\n",
       "         [0.25135776, 0.5254652 , 0.15957826, ..., 0.4634861 ,\n",
       "          0.93730724, 0.13007902],\n",
       "         [0.26109582, 0.5220466 , 0.15758617, ..., 0.4602871 ,\n",
       "          0.92858046, 0.12985009]],\n",
       "\n",
       "        [[0.5469892 , 0.85574704, 0.88896304, ..., 0.56600523,\n",
       "          0.8326839 , 0.8713486 ],\n",
       "         [0.5169891 , 0.84587336, 0.9298277 , ..., 0.5863031 ,\n",
       "          0.9052783 , 0.91067934],\n",
       "         [0.51694065, 0.8458574 , 0.92989373, ..., 0.5863359 ,\n",
       "          0.90539575, 0.9107429 ],\n",
       "         ...,\n",
       "         [0.5173293 , 0.84598535, 0.9293645 , ..., 0.58607304,\n",
       "          0.90445554, 0.91023356],\n",
       "         [0.516965  , 0.8458654 , 0.9298607 , ..., 0.5863195 ,\n",
       "          0.905337  , 0.9107111 ],\n",
       "         [0.51746726, 0.8460307 , 0.9291764 , ..., 0.5859796 ,\n",
       "          0.9041214 , 0.9100525 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.04194095, 0.15901402, 0.11496028, ..., 0.7029679 ,\n",
       "          0.14448768, 0.66052234],\n",
       "         [0.05676362, 0.17819655, 0.16383332, ..., 0.6910377 ,\n",
       "          0.18958266, 0.66870004],\n",
       "         [0.05239812, 0.17013164, 0.14586769, ..., 0.69751084,\n",
       "          0.17561558, 0.6644983 ],\n",
       "         ...,\n",
       "         [0.05154895, 0.16884498, 0.1427902 , ..., 0.6984244 ,\n",
       "          0.17297882, 0.66389054],\n",
       "         [0.24775155, 0.3705205 , 0.7124581 , ..., 0.6045166 ,\n",
       "          0.75505024, 0.73335385],\n",
       "         [0.13618226, 0.2557167 , 0.3883393 , ..., 0.6580667 ,\n",
       "          0.4240245 , 0.6937632 ]],\n",
       "\n",
       "        [[0.49122894, 0.93199   , 0.40811527, ..., 0.00401068,\n",
       "          0.797632  , 0.87456584],\n",
       "         [0.49122894, 0.93199   , 0.40811527, ..., 0.00401068,\n",
       "          0.797632  , 0.87456584],\n",
       "         [0.49122894, 0.93199   , 0.40811527, ..., 0.00401068,\n",
       "          0.797632  , 0.87456584],\n",
       "         ...,\n",
       "         [0.49122894, 0.93199   , 0.40811527, ..., 0.00401068,\n",
       "          0.797632  , 0.87456584],\n",
       "         [0.49122894, 0.93199   , 0.40811527, ..., 0.00401068,\n",
       "          0.797632  , 0.87456584],\n",
       "         [0.49122894, 0.93199   , 0.40811527, ..., 0.00401068,\n",
       "          0.797632  , 0.87456584]],\n",
       "\n",
       "        [[0.928782  , 0.37257314, 0.05044067, ..., 0.15079486,\n",
       "          0.38581383, 0.6997006 ],\n",
       "         [0.928782  , 0.37257317, 0.05044072, ..., 0.15079497,\n",
       "          0.38581386, 0.69970053],\n",
       "         [0.92861956, 0.37266913, 0.05051157, ..., 0.15105835,\n",
       "          0.38585663, 0.6995157 ],\n",
       "         ...,\n",
       "         [0.928782  , 0.37257317, 0.05044067, ..., 0.1507949 ,\n",
       "          0.38581386, 0.6997006 ],\n",
       "         [0.928782  , 0.37257314, 0.05044069, ..., 0.15079488,\n",
       "          0.38581383, 0.6997006 ],\n",
       "         [0.928782  , 0.37257314, 0.05044067, ..., 0.15079486,\n",
       "          0.38581383, 0.6997006 ]]],\n",
       "\n",
       "\n",
       "       [[[0.9669016 , 0.3504637 , 0.47626057, ..., 0.41187006,\n",
       "          0.29497036, 0.28644615],\n",
       "         [0.96690214, 0.3504627 , 0.47625986, ..., 0.41187072,\n",
       "          0.29497087, 0.28644598],\n",
       "         [0.96681416, 0.35064468, 0.4763985 , ..., 0.4117593 ,\n",
       "          0.29488504, 0.28647617],\n",
       "         ...,\n",
       "         [0.96690184, 0.3504633 , 0.4762603 , ..., 0.41187033,\n",
       "          0.29497057, 0.2864461 ],\n",
       "         [0.9667314 , 0.35081565, 0.47652873, ..., 0.41165444,\n",
       "          0.29480428, 0.28650448],\n",
       "         [0.96683323, 0.35060513, 0.47636834, ..., 0.41178346,\n",
       "          0.29490364, 0.28646958]],\n",
       "\n",
       "        [[0.91957134, 0.6984782 , 0.8899221 , ..., 0.4794724 ,\n",
       "          0.5069558 , 0.39064384],\n",
       "         [0.92656136, 0.6919954 , 0.932808  , ..., 0.44390827,\n",
       "          0.5956051 , 0.23863576],\n",
       "         [0.8076606 , 0.70252603, 0.7838686 , ..., 0.4837731 ,\n",
       "          0.40813506, 0.48425892],\n",
       "         ...,\n",
       "         [0.88691527, 0.7203803 , 0.73835623, ..., 0.5981345 ,\n",
       "          0.20378175, 0.90413964],\n",
       "         [0.93670595, 0.68462205, 0.983208  , ..., 0.4038176 ,\n",
       "          0.69732594, 0.06575305],\n",
       "         [0.88822687, 0.7195294 , 0.74427474, ..., 0.5935334 ,\n",
       "          0.21557437, 0.88419724]],\n",
       "\n",
       "        [[0.0412699 , 0.34504366, 0.2489847 , ..., 0.24881494,\n",
       "          0.18727744, 0.8900969 ],\n",
       "         [0.0412699 , 0.34504366, 0.2489847 , ..., 0.24881494,\n",
       "          0.18727744, 0.8900969 ],\n",
       "         [0.0412699 , 0.34504366, 0.2489847 , ..., 0.24881494,\n",
       "          0.18727744, 0.8900969 ],\n",
       "         ...,\n",
       "         [0.0412699 , 0.34504366, 0.2489847 , ..., 0.24881494,\n",
       "          0.18727744, 0.8900969 ],\n",
       "         [0.0412699 , 0.34504366, 0.2489847 , ..., 0.24881494,\n",
       "          0.18727744, 0.8900969 ],\n",
       "         [0.0412699 , 0.34504366, 0.2489847 , ..., 0.24881494,\n",
       "          0.18727744, 0.8900969 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.08218158, 0.2738476 , 0.11209553, ..., 0.13952604,\n",
       "          0.7099918 , 0.11111142],\n",
       "         [0.0733216 , 0.2736063 , 0.09799311, ..., 0.13722913,\n",
       "          0.7173868 , 0.09215835],\n",
       "         [0.45522213, 0.33000675, 0.86063063, ..., 0.04549629,\n",
       "          0.24791121, 0.9481179 ],\n",
       "         ...,\n",
       "         [0.08760396, 0.27460822, 0.12272313, ..., 0.13841818,\n",
       "          0.70348406, 0.12316384],\n",
       "         [0.08574317, 0.2754917 , 0.12304782, ..., 0.13400318,\n",
       "          0.7019208 , 0.12012528],\n",
       "         [0.4413861 , 0.32865518, 0.83516526, ..., 0.04601454,\n",
       "          0.26271218, 0.9175182 ]],\n",
       "\n",
       "        [[0.35596868, 0.74465203, 0.38745645, ..., 0.03569449,\n",
       "          0.83633584, 0.3064952 ],\n",
       "         [0.35010383, 0.7463532 , 0.393145  , ..., 0.06425992,\n",
       "          0.80279154, 0.336343  ],\n",
       "         [0.351947  , 0.74589723, 0.39140725, ..., 0.05594114,\n",
       "          0.81243646, 0.32763073],\n",
       "         ...,\n",
       "         [0.35346374, 0.74542886, 0.38991818, ..., 0.04831532,\n",
       "          0.8214364 , 0.31966963],\n",
       "         [0.35613388, 0.74460405, 0.3872962 , ..., 0.03488999,\n",
       "          0.83728045, 0.3056545 ],\n",
       "         [0.31023827, 0.7579125 , 0.43181053, ..., 0.25839537,\n",
       "          0.57482624, 0.5391941 ]],\n",
       "\n",
       "        [[0.46818718, 0.8027199 , 0.65780324, ..., 0.37242487,\n",
       "          0.3266229 , 0.865349  ],\n",
       "         [0.4684513 , 0.8047416 , 0.6590411 , ..., 0.37296456,\n",
       "          0.327329  , 0.8664849 ],\n",
       "         [0.46851015, 0.8051954 , 0.6593191 , ..., 0.37308565,\n",
       "          0.32748774, 0.8667406 ],\n",
       "         ...,\n",
       "         [0.46721202, 0.795232  , 0.6532169 , ..., 0.37042657,\n",
       "          0.32400683, 0.86113685],\n",
       "         [0.46839377, 0.8043038 , 0.65877324, ..., 0.37284756,\n",
       "          0.32717603, 0.8662394 ],\n",
       "         [0.46860653, 0.8059351 , 0.6597722 , ..., 0.37328297,\n",
       "          0.32774585, 0.86715645]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.25157353, 0.8156299 , 0.9696485 , ..., 0.11549618,\n",
       "          0.05905419, 0.19605015],\n",
       "         [0.20114699, 0.8704688 , 0.9782493 , ..., 0.15735628,\n",
       "          0.28805652, 0.15408537],\n",
       "         [0.2555381 , 0.81131846, 0.96897227, ..., 0.11220511,\n",
       "          0.04104988, 0.19934945],\n",
       "         ...,\n",
       "         [0.236007  , 0.83255863, 0.9723036 , ..., 0.12841831,\n",
       "          0.12974669, 0.18309574],\n",
       "         [0.0857732 , 0.99593806, 0.9979279 , ..., 0.2531304 ,\n",
       "          0.81200427, 0.05807173],\n",
       "         [0.08519485, 0.99656683, 0.99802643, ..., 0.2536105 ,\n",
       "          0.8146306 , 0.05759043]],\n",
       "\n",
       "        [[0.47562614, 0.7522876 , 0.54215014, ..., 0.27793562,\n",
       "          0.66662514, 0.31228295],\n",
       "         [0.4756261 , 0.7522876 , 0.54215014, ..., 0.27793562,\n",
       "          0.6666251 , 0.31228295],\n",
       "         [0.4756261 , 0.7522876 , 0.54215014, ..., 0.27793562,\n",
       "          0.66662514, 0.31228292],\n",
       "         ...,\n",
       "         [0.4756261 , 0.7522876 , 0.54215014, ..., 0.27793562,\n",
       "          0.66662514, 0.31228292],\n",
       "         [0.4756261 , 0.7522876 , 0.54215014, ..., 0.27793562,\n",
       "          0.66662514, 0.31228292],\n",
       "         [0.4756261 , 0.7522876 , 0.54215014, ..., 0.27793562,\n",
       "          0.66662514, 0.31228292]],\n",
       "\n",
       "        [[0.25114763, 0.30392635, 0.42084613, ..., 0.2655778 ,\n",
       "          0.75074625, 0.38866845],\n",
       "         [0.09496567, 0.3371394 , 0.15164997, ..., 0.2390408 ,\n",
       "          0.9303199 , 0.38349065],\n",
       "         [0.09473625, 0.33718914, 0.15125196, ..., 0.23900245,\n",
       "          0.93058383, 0.3834837 ],\n",
       "         ...,\n",
       "         [0.09471406, 0.33719286, 0.15121639, ..., 0.23899807,\n",
       "          0.9306093 , 0.38348225],\n",
       "         [0.09470894, 0.33719394, 0.15120755, ..., 0.23899719,\n",
       "          0.9306151 , 0.38348207],\n",
       "         [0.09476997, 0.337181  , 0.15131272, ..., 0.23900759,\n",
       "          0.9305451 , 0.38348413]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.51079243, 0.22945178, 0.12484112, ..., 0.0804709 ,\n",
       "          0.5804215 , 0.6910663 ],\n",
       "         [0.524994  , 0.23257506, 0.12065826, ..., 0.10810636,\n",
       "          0.563588  , 0.69385344],\n",
       "         [0.5107788 , 0.22944877, 0.12484512, ..., 0.0804444 ,\n",
       "          0.58043754, 0.6910636 ],\n",
       "         ...,\n",
       "         [0.5109154 , 0.22947884, 0.12480488, ..., 0.08071033,\n",
       "          0.5802756 , 0.6910904 ],\n",
       "         [0.57480913, 0.24353059, 0.10598606, ..., 0.20504314,\n",
       "          0.5045417 , 0.7036298 ],\n",
       "         [0.5107886 , 0.22945094, 0.12484222, ..., 0.08046362,\n",
       "          0.58042586, 0.69106555]],\n",
       "\n",
       "        [[0.0490919 , 0.47022688, 0.54759806, ..., 0.67998135,\n",
       "          0.68489623, 0.0854506 ],\n",
       "         [0.0495711 , 0.46992102, 0.5479043 , ..., 0.6801299 ,\n",
       "          0.68466616, 0.08621186],\n",
       "         [0.04906201, 0.4701928 , 0.54764694, ..., 0.6799636 ,\n",
       "          0.6848077 , 0.08554821],\n",
       "         ...,\n",
       "         [0.04932654, 0.47016385, 0.5476371 , ..., 0.68006796,\n",
       "          0.6849514 , 0.08558675],\n",
       "         [0.0491229 , 0.47027022, 0.5475371 , ..., 0.680001  ,\n",
       "          0.6850034 , 0.08532763],\n",
       "         [0.04912467, 0.4702507 , 0.54756176, ..., 0.67999864,\n",
       "          0.68496704, 0.08538062]],\n",
       "\n",
       "        [[0.8667158 , 0.21674319, 0.35563552, ..., 0.5723915 ,\n",
       "          0.14902294, 0.20597132],\n",
       "         [0.80037796, 0.21364531, 0.4121693 , ..., 0.58399796,\n",
       "          0.22421236, 0.23432194],\n",
       "         [0.9116613 , 0.22055851, 0.31692225, ..., 0.564693  ,\n",
       "          0.09897902, 0.18678178],\n",
       "         ...,\n",
       "         [0.88684434, 0.21809347, 0.33834693, ..., 0.5688853 ,\n",
       "          0.1263851 , 0.19737105],\n",
       "         [0.76826644, 0.21093696, 0.43938807, ..., 0.5891125 ,\n",
       "          0.25909036, 0.24773133],\n",
       "         [0.9250515 , 0.22069836, 0.3056508 , ..., 0.5623392 ,\n",
       "          0.083658  , 0.1811097 ]]],\n",
       "\n",
       "\n",
       "       [[[0.3021145 , 0.3913666 , 0.48647034, ..., 0.63501716,\n",
       "          0.07202339, 0.2870823 ],\n",
       "         [0.3021145 , 0.3913666 , 0.48647034, ..., 0.63501716,\n",
       "          0.07202339, 0.2870823 ],\n",
       "         [0.3021145 , 0.3913666 , 0.48647034, ..., 0.63501716,\n",
       "          0.07202339, 0.2870823 ],\n",
       "         ...,\n",
       "         [0.3021145 , 0.3913666 , 0.48647034, ..., 0.63501716,\n",
       "          0.07202339, 0.2870823 ],\n",
       "         [0.3021145 , 0.3913666 , 0.48647034, ..., 0.63501716,\n",
       "          0.07202339, 0.2870823 ],\n",
       "         [0.3021145 , 0.3913666 , 0.48647034, ..., 0.63501716,\n",
       "          0.07202339, 0.2870823 ]],\n",
       "\n",
       "        [[0.5768465 , 0.00174451, 0.1320466 , ..., 0.5484445 ,\n",
       "          0.23248507, 0.25913742],\n",
       "         [0.5768465 , 0.00174451, 0.13204663, ..., 0.5484445 ,\n",
       "          0.23248512, 0.25913742],\n",
       "         [0.5768464 , 0.00174452, 0.13204663, ..., 0.54844445,\n",
       "          0.2324851 , 0.25913742],\n",
       "         ...,\n",
       "         [0.5768456 , 0.00174465, 0.1320476 , ..., 0.5484442 ,\n",
       "          0.23248626, 0.25913823],\n",
       "         [0.5768464 , 0.00174452, 0.13204667, ..., 0.5484445 ,\n",
       "          0.23248516, 0.25913745],\n",
       "         [0.5768447 , 0.0017448 , 0.13204862, ..., 0.54844385,\n",
       "          0.2324875 , 0.25913912]],\n",
       "\n",
       "        [[0.88991433, 0.32612053, 0.8519477 , ..., 0.86663353,\n",
       "          0.60033995, 0.02457438],\n",
       "         [0.88351965, 0.3364606 , 0.83155245, ..., 0.8399195 ,\n",
       "          0.6124642 , 0.02948121],\n",
       "         [0.77953964, 0.50459677, 0.49991283, ..., 0.40553272,\n",
       "          0.8096133 , 0.10926834],\n",
       "         ...,\n",
       "         [0.86995625, 0.3583928 , 0.78829235, ..., 0.7832567 ,\n",
       "          0.638181  , 0.03988884],\n",
       "         [0.88032204, 0.34163126, 0.8213536 , ..., 0.8265609 ,\n",
       "          0.6185272 , 0.03193484],\n",
       "         [0.89660156, 0.31530735, 0.8732762 , ..., 0.8945699 ,\n",
       "          0.5876609 , 0.0194431 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.20006059, 0.617822  , 0.5621847 , ..., 0.5564159 ,\n",
       "          0.10544681, 0.36829725],\n",
       "         [0.20003177, 0.61776084, 0.5622746 , ..., 0.5564048 ,\n",
       "          0.10509635, 0.36820272],\n",
       "         [0.20002507, 0.6178369 , 0.5622419 , ..., 0.5563574 ,\n",
       "          0.1053345 , 0.36820093],\n",
       "         ...,\n",
       "         [0.20003042, 0.6177514 , 0.5622827 , ..., 0.5564076 ,\n",
       "          0.10505664, 0.3681968 ],\n",
       "         [0.20002931, 0.617749  , 0.5622862 , ..., 0.5564072 ,\n",
       "          0.10504293, 0.36819318],\n",
       "         [0.20003675, 0.61780673, 0.5622381 , ..., 0.5563892 ,\n",
       "          0.10528202, 0.36822698]],\n",
       "\n",
       "        [[0.88340986, 0.712783  , 0.531372  , ..., 0.5095585 ,\n",
       "          0.09421504, 0.29463723],\n",
       "         [0.8828165 , 0.7130671 , 0.5306034 , ..., 0.50941366,\n",
       "          0.09451889, 0.2951308 ],\n",
       "         [0.8819699 , 0.71347255, 0.52950674, ..., 0.50920695,\n",
       "          0.09495243, 0.2958351 ],\n",
       "         ...,\n",
       "         [0.8834658 , 0.7127562 , 0.53144455, ..., 0.5095722 ,\n",
       "          0.09418637, 0.29459065],\n",
       "         [0.8831785 , 0.7128937 , 0.5310723 , ..., 0.509502  ,\n",
       "          0.09433349, 0.29482964],\n",
       "         [0.88334996, 0.71281165, 0.5312945 , ..., 0.5095439 ,\n",
       "          0.09424567, 0.29468697]],\n",
       "\n",
       "        [[0.3009713 , 0.5286472 , 0.6635859 , ..., 0.33495587,\n",
       "          0.5548664 , 0.81138015],\n",
       "         [0.29770988, 0.5280969 , 0.6626448 , ..., 0.33108562,\n",
       "          0.558701  , 0.815655  ],\n",
       "         [0.2961493 , 0.52783334, 0.6621951 , ..., 0.32923537,\n",
       "          0.56053555, 0.8176984 ],\n",
       "         ...,\n",
       "         [0.29618582, 0.5278394 , 0.6622057 , ..., 0.32927895,\n",
       "          0.5604925 , 0.8176502 ],\n",
       "         [0.29623196, 0.5278472 , 0.66221917, ..., 0.32933438,\n",
       "          0.5604382 , 0.81758887],\n",
       "         [0.29622743, 0.527846  , 0.66221887, ..., 0.32933152,\n",
       "          0.56044304, 0.8175918 ]]],\n",
       "\n",
       "\n",
       "       [[[0.4814209 , 0.3525365 , 0.778021  , ..., 0.07857153,\n",
       "          0.8808428 , 0.47726157],\n",
       "         [0.48183447, 0.35320216, 0.7778834 , ..., 0.07874805,\n",
       "          0.88084364, 0.4770259 ],\n",
       "         [0.490774  , 0.3624407 , 0.7792578 , ..., 0.08186139,\n",
       "          0.87722516, 0.48229593],\n",
       "         ...,\n",
       "         [0.5020306 , 0.37384677, 0.7815436 , ..., 0.08373759,\n",
       "          0.8728215 , 0.4916688 ],\n",
       "         [0.4806896 , 0.35202917, 0.7776824 , ..., 0.07844076,\n",
       "          0.88130033, 0.4762284 ],\n",
       "         [0.72362363, 0.6004515 , 0.821478  , ..., 0.13932608,\n",
       "          0.7847368 , 0.651209  ]],\n",
       "\n",
       "        [[0.43244013, 0.737459  , 0.41346645, ..., 0.29685912,\n",
       "          0.91884   , 0.47648624],\n",
       "         [0.43246314, 0.73750794, 0.4135441 , ..., 0.29692137,\n",
       "          0.9187906 , 0.47652417],\n",
       "         [0.43258673, 0.7376284 , 0.41380695, ..., 0.29713792,\n",
       "          0.918766  , 0.47658542],\n",
       "         ...,\n",
       "         [0.43194366, 0.7405177 , 0.4161762 , ..., 0.2989989 ,\n",
       "          0.9121866 , 0.4799425 ],\n",
       "         [0.43221378, 0.73762   , 0.4133875 , ..., 0.29678974,\n",
       "          0.9181253 , 0.47677982],\n",
       "         [0.43244353, 0.73746264, 0.4134739 , ..., 0.29686517,\n",
       "          0.9188394 , 0.4764881 ]],\n",
       "\n",
       "        [[0.99611497, 0.62634015, 0.78329265, ..., 0.2787584 ,\n",
       "          0.53264976, 0.00536633],\n",
       "         [0.99611497, 0.62634015, 0.78329265, ..., 0.2787584 ,\n",
       "          0.53264976, 0.00536634],\n",
       "         [0.99611497, 0.62634015, 0.78329265, ..., 0.2787584 ,\n",
       "          0.53264976, 0.00536633],\n",
       "         ...,\n",
       "         [0.99611497, 0.62634015, 0.78329265, ..., 0.2787584 ,\n",
       "          0.53264976, 0.00536633],\n",
       "         [0.99611497, 0.62634015, 0.78329265, ..., 0.2787584 ,\n",
       "          0.53264976, 0.00536633],\n",
       "         [0.99611497, 0.62634015, 0.78329265, ..., 0.2787584 ,\n",
       "          0.53264976, 0.00536633]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0849092 , 0.7432635 , 0.14930677, ..., 0.8229368 ,\n",
       "          0.01502573, 0.88845   ],\n",
       "         [0.0849092 , 0.7432635 , 0.14930677, ..., 0.8229368 ,\n",
       "          0.01502573, 0.88845   ],\n",
       "         [0.0849092 , 0.7432635 , 0.14930677, ..., 0.8229368 ,\n",
       "          0.01502573, 0.88845   ],\n",
       "         ...,\n",
       "         [0.0849092 , 0.7432635 , 0.14930677, ..., 0.8229368 ,\n",
       "          0.01502573, 0.88845   ],\n",
       "         [0.0849092 , 0.7432635 , 0.14930677, ..., 0.8229368 ,\n",
       "          0.01502573, 0.88845   ],\n",
       "         [0.0849092 , 0.7432635 , 0.14930677, ..., 0.8229368 ,\n",
       "          0.01502573, 0.88845   ]],\n",
       "\n",
       "        [[0.18731126, 0.7111829 , 0.58554727, ..., 0.51453185,\n",
       "          0.09769899, 0.36308914],\n",
       "         [0.06108114, 0.28759795, 0.8006456 , ..., 0.27991122,\n",
       "          0.14950275, 0.1051375 ],\n",
       "         [0.05470222, 0.2662668 , 0.8114817 , ..., 0.26807317,\n",
       "          0.15206043, 0.09215859],\n",
       "         ...,\n",
       "         [0.05363636, 0.2597479 , 0.81534714, ..., 0.2651452 ,\n",
       "          0.15391916, 0.08810338],\n",
       "         [0.03850421, 0.21197349, 0.83902913, ..., 0.23798971,\n",
       "          0.15869337, 0.05909159],\n",
       "         [0.03043727, 0.18493181, 0.8527685 , ..., 0.22300099,\n",
       "          0.16197307, 0.04263119]],\n",
       "\n",
       "        [[0.11091756, 0.8476263 , 0.7112093 , ..., 0.92011523,\n",
       "          0.78236544, 0.33197725],\n",
       "         [0.11187052, 0.84786046, 0.710182  , ..., 0.92018366,\n",
       "          0.78268504, 0.33265004],\n",
       "         [0.11115203, 0.8477126 , 0.71095276, ..., 0.92009413,\n",
       "          0.7823965 , 0.33212876],\n",
       "         ...,\n",
       "         [0.11099114, 0.847646  , 0.7111297 , ..., 0.92011845,\n",
       "          0.78238755, 0.3320284 ],\n",
       "         [0.11091334, 0.84762436, 0.7112139 , ..., 0.9201162 ,\n",
       "          0.78236556, 0.33197471],\n",
       "         [0.11096969, 0.8476407 , 0.7111529 , ..., 0.92011714,\n",
       "          0.7823806 , 0.33201334]]]], dtype=float32)>"
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = history_qa_ids\n",
    "attended = tf.matmul(alpha, x3)\n",
    "attended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = tf.unstack(attended, axis=1)\n",
    "n = len(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = tmp[0]\n",
    "for i in range(1, n):\n",
    "    mean += tmp[i]\n",
    "mean = tf.cast(mean, tf.float32)\n",
    "attend = mean / n\n",
    "attend.shape, attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([384, 768])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform([1,384,768])\n",
    "x= tf.squeeze(x, axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def scoring(x1, x2):\n",
    "\n",
    "    x1_rep = x1#1 * 384 * 768\n",
    "    x2_rep = x2#1 * 114 * 768\n",
    "\n",
    "    # scores = x1_rep.bmm(x2_rep.transpose(1, 2))\n",
    "    x2_rep = tf.transpose(x2_rep, perm=[0, 2, 1])\n",
    "    scores = tf.matmul(x1_rep, x2_rep)#1 * 384 * 114\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.random.uniform([12,384,768])\n",
    "h1 = tf.random.uniform([12,64,768])\n",
    "h2 = tf.zeros([12,208,768])\n",
    "history = tf.concat([h1,h2], axis=1)\n",
    "\n",
    "h1 = tf.ones([12,64])\n",
    "h2 = tf.zeros([12,208])\n",
    "mask = tf.concat([h1,h2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.97554016 0.2138685  0.4384668  ... 0.7832124  0.8633803  0.20647144]\n",
      "  [0.6306399  0.14853203 0.49749684 ... 0.7296274  0.76150525 0.06837916]\n",
      "  [0.45558774 0.7244091  0.8362372  ... 0.3110727  0.6083883  0.08332443]\n",
      "  ...\n",
      "  [0.45657325 0.02335835 0.5152613  ... 0.3923632  0.5956837  0.04495895]\n",
      "  [0.03296769 0.7556968  0.94366395 ... 0.82735443 0.8621496  0.65742266]\n",
      "  [0.9088532  0.49004745 0.62592053 ... 0.5901555  0.73852825 0.33289838]]\n",
      "\n",
      " [[0.20606971 0.45240033 0.05021191 ... 0.20194292 0.45343554 0.9482714 ]\n",
      "  [0.9467952  0.63757205 0.3852414  ... 0.14810884 0.00824761 0.74758506]\n",
      "  [0.9879557  0.3669536  0.19919884 ... 0.26906836 0.12537587 0.1531595 ]\n",
      "  ...\n",
      "  [0.1709044  0.4179517  0.00515926 ... 0.13712788 0.8612112  0.58745146]\n",
      "  [0.23606515 0.30902517 0.9543301  ... 0.3784498  0.17841649 0.0513016 ]\n",
      "  [0.12174988 0.88315105 0.71752346 ... 0.70164454 0.34793198 0.845577  ]]\n",
      "\n",
      " [[0.7108731  0.07919455 0.86368597 ... 0.89878774 0.27103567 0.473184  ]\n",
      "  [0.6090425  0.04634905 0.13758266 ... 0.41311133 0.3433025  0.80692804]\n",
      "  [0.6693759  0.91811466 0.37746525 ... 0.85040915 0.53908086 0.72076535]\n",
      "  ...\n",
      "  [0.00627744 0.37334692 0.91135824 ... 0.7546601  0.49580085 0.43866265]\n",
      "  [0.9943732  0.7025589  0.823665   ... 0.02868736 0.00447893 0.9413104 ]\n",
      "  [0.5068779  0.3522215  0.6296495  ... 0.49009132 0.8434726  0.16073596]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.7315016  0.9553325  0.5810795  ... 0.31623244 0.25774157 0.8474637 ]\n",
      "  [0.22466087 0.35603082 0.85053897 ... 0.6873243  0.6021614  0.58169055]\n",
      "  [0.7212585  0.45778775 0.85226583 ... 0.17202342 0.4932654  0.69906676]\n",
      "  ...\n",
      "  [0.25774074 0.26694953 0.21871638 ... 0.23551989 0.41180742 0.27271402]\n",
      "  [0.6434063  0.76909363 0.52836573 ... 0.08623004 0.28219283 0.10220623]\n",
      "  [0.7158097  0.04827929 0.31430888 ... 0.93445766 0.23554742 0.283095  ]]\n",
      "\n",
      " [[0.13473403 0.8960284  0.5795822  ... 0.81851447 0.2118026  0.5846479 ]\n",
      "  [0.9071548  0.40224397 0.931983   ... 0.52813923 0.34462798 0.42686558]\n",
      "  [0.2944293  0.610975   0.00728154 ... 0.99443996 0.11974335 0.9171258 ]\n",
      "  ...\n",
      "  [0.04363024 0.0383867  0.6748004  ... 0.517102   0.4177587  0.7752714 ]\n",
      "  [0.91297984 0.26753438 0.40161955 ... 0.41626823 0.39391947 0.770381  ]\n",
      "  [0.8520831  0.43615508 0.46757984 ... 0.5292399  0.767396   0.76514137]]\n",
      "\n",
      " [[0.05342758 0.50313973 0.57759917 ... 0.08710241 0.17289889 0.30420256]\n",
      "  [0.5646647  0.89641905 0.09365976 ... 0.99049544 0.43822396 0.67475843]\n",
      "  [0.46276903 0.423684   0.37111688 ... 0.79417753 0.89155054 0.6397202 ]\n",
      "  ...\n",
      "  [0.64152277 0.98942995 0.4467764  ... 0.64744866 0.35970843 0.14448142]\n",
      "  [0.50241673 0.46883678 0.28678703 ... 0.38706887 0.65881205 0.16544497]\n",
      "  [0.64478827 0.23395967 0.9071475  ... 0.9568893  0.32142127 0.25765502]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'LogicalNot_3:0' shape=(12, 272) dtype=bool>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = ~tf.cast(mask, tf.bool)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fill_inf(matrix, mask):\n",
    "    negmask = 1 - mask\n",
    "    num = 3.4 * math.pow(10, 38)\n",
    "    return (matrix * mask) + (-((negmask * num + num) - num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_1:0' shape=(12, 384, 768) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scores = scoring(input_tensor, history)\n",
    "mask = tf.tile(tf.expand_dims(mask, axis=1), [1, 384, 1])\n",
    "scores = mask_fill_inf(scores, mask)\n",
    "\n",
    "# empty_mask = tf.tile(mask, [1, scores.shape[1], 1])#矩阵扩张 12，12，384，114\n",
    "# score = tf.cast(scores, tf.float32)\n",
    "# empty_mask = tf.cast(empty_mask, tf.float32)\n",
    "scores = tf.reshape(scores, [-1, 272])\n",
    "alpha_flat = tf.nn.softmax(scores, axis=1)\n",
    "alpha = tf.reshape(alpha_flat, [-1, 384, 272])\n",
    "attend = tf.matmul(alpha, history)\n",
    "attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.5112139  0.96938694 0.828981   ... 0.6151375  0.18611401 0.15173799]\n",
      "  [0.68687284 0.778277   0.43345213 ... 0.5198698  0.38006687 0.5942273 ]\n",
      "  [0.45146805 0.714343   0.86227185 ... 0.60721296 0.31994036 0.2914255 ]\n",
      "  ...\n",
      "  [0.5458357  0.6607005  0.6211204  ... 0.55533254 0.40247008 0.3825738 ]\n",
      "  [0.5060566  0.98119444 0.84461886 ... 0.6170002  0.17991577 0.14714915]\n",
      "  [0.7933887  0.70581114 0.57987714 ... 0.23000601 0.49147522 0.33478218]]\n",
      "\n",
      " [[0.65834147 0.632716   0.24272782 ... 0.85494405 0.7245021  0.08654165]\n",
      "  [0.6065849  0.6122038  0.24836095 ... 0.8260442  0.70458883 0.1148698 ]\n",
      "  [0.46667635 0.6144969  0.39790982 ... 0.7130008  0.48890018 0.45273292]\n",
      "  ...\n",
      "  [0.08696221 0.42302507 0.47148317 ... 0.6060282  0.36520064 0.2826589 ]\n",
      "  [0.5365677  0.95083153 0.6863917  ... 0.86177826 0.17812468 0.3139429 ]\n",
      "  [0.63767415 0.63929355 0.2406481  ... 0.8408814  0.72354865 0.09266835]]\n",
      "\n",
      " [[0.40365347 0.09671991 0.53499097 ... 0.6887844  0.5393072  0.6245417 ]\n",
      "  [0.27352807 0.20935144 0.5573049  ... 0.74397916 0.44990236 0.4603479 ]\n",
      "  [0.6113924  0.19378583 0.30139634 ... 0.68589467 0.7222783  0.38011578]\n",
      "  ...\n",
      "  [0.10728953 0.14569058 0.7373241  ... 0.27995378 0.61352587 0.39618525]\n",
      "  [0.31674105 0.45373583 0.61394125 ... 0.4670975  0.623726   0.54907525]\n",
      "  [0.30032173 0.20847467 0.64531296 ... 0.7012602  0.564338   0.5549452 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.73688996 0.53937584 0.48992786 ... 0.51008695 0.7651529  0.3282734 ]\n",
      "  [0.31429893 0.27916986 0.63241845 ... 0.2856816  0.57391924 0.65870744]\n",
      "  [0.8316232  0.49799722 0.2798498  ... 0.3821602  0.62957704 0.5609432 ]\n",
      "  ...\n",
      "  [0.7653061  0.48591316 0.70539033 ... 0.4570944  0.7273256  0.34398243]\n",
      "  [0.7837429  0.6095226  0.5513183  ... 0.65112984 0.85411346 0.14776544]\n",
      "  [0.8252541  0.38664395 0.25738645 ... 0.28494743 0.6225043  0.57672626]]\n",
      "\n",
      " [[0.4782056  0.40410778 0.31527176 ... 0.47176707 0.91269976 0.5625705 ]\n",
      "  [0.43424165 0.5078327  0.39909184 ... 0.57872075 0.45639494 0.4732706 ]\n",
      "  [0.29720387 0.54398036 0.5165684  ... 0.6493915  0.7351364  0.77413064]\n",
      "  ...\n",
      "  [0.3660154  0.44778782 0.29762584 ... 0.31057188 0.7267591  0.70853657]\n",
      "  [0.73738575 0.78378373 0.4180046  ... 0.46400377 0.8799647  0.43119794]\n",
      "  [0.34213522 0.61389977 0.47014546 ... 0.66569275 0.6680834  0.69746006]]\n",
      "\n",
      " [[0.8007177  0.58254755 0.5219883  ... 0.34580162 0.20909072 0.41155106]\n",
      "  [0.16204518 0.18418854 0.7764652  ... 0.2223506  0.22069074 0.5580644 ]\n",
      "  [0.7579886  0.9149809  0.2375921  ... 0.09187196 0.7201271  0.35228512]\n",
      "  ...\n",
      "  [0.48274556 0.82099086 0.51441085 ... 0.4998171  0.37867916 0.38216323]\n",
      "  [0.30367395 0.59717566 0.6811785  ... 0.60712236 0.14606114 0.62238497]\n",
      "  [0.557854   0.6434949  0.72747743 ... 0.406651   0.3940507  0.4834349 ]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(attend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.reduce_mean(score, axis=1)\n",
    "int(mask[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(x1, x2):\n",
    "    '''\n",
    "        Input:\n",
    "        x1: batch x word_num1 x dim\n",
    "        x2: batch x word_num2 x dim\n",
    "        Output:\n",
    "        scores: batch x word_num1 x word_num2\n",
    "        '''\n",
    "    # x1 = dropout(x1, p = dropout_p, training = self.training)\n",
    "    # x2 = dropout(x2, p = dropout_p, training = self.training)\n",
    "    x1_rep = x1#4 * 384 * 768\n",
    "    x2_rep = x2#4 * 114 * 768\n",
    "\n",
    "    # scores = x1_rep.bmm(x2_rep.transpose(1, 2))\n",
    "    x2_rep = tf.transpose(x2_rep, perm=[0, 2, 1])\n",
    "    scores = tf.einsum('aik,akj->aij', x1_rep, x2_rep)#4 * 384 * 114\n",
    "    # x2_rep = tf.transpose(x2_rep, perm=[0, 1, 3, 2])#? * 12 * 768 * 114\n",
    "    # scores = tf.einsum('abij,abjk->abik', x1_rep, x2_rep)#? * 12 * 384 * 114\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 384, 768)\n",
      "599748.0\n",
      "590227.9\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tf.random.uniform([4,384,768])\n",
    "history_output = tf.random.uniform([4,12,114,768])\n",
    "history_mask = tf.random.uniform([4,12,114])\n",
    "\n",
    "num1 = history_output.shape[0]\n",
    "num2 = history_output.shape[1]\n",
    "\n",
    "single_inputs = tf.split(input_tensor, num1, axis=0)\n",
    "single_historys = tf.split(history_output, num1, axis=0)\n",
    "single_masks = tf.split(history_mask, num1, axis=0)\n",
    "# print(single_inputs[0].shape)\n",
    "new_input = []\n",
    "for single_input, single_history, single_mask in zip(single_inputs, single_historys, single_masks):\n",
    "    each_historys = tf.split(single_history, num2, axis=1)\n",
    " \n",
    "    each_masks = tf.split(single_mask, num2, axis=1)\n",
    "    new_his = []\n",
    "    new_mask = []\n",
    "    for each_history, each_mask in zip(each_historys, each_masks):\n",
    "        each_history = tf.squeeze(each_history, axis=1)\n",
    "        each_mask = tf.squeeze(each_mask, axis=1)\n",
    "        new_his.append(each_history)#把不是0的history找出来\n",
    "        new_mask.append(each_mask)\n",
    "#     print(new_his[0].shape)\n",
    "    history = tf.concat([i for i in new_his], axis=0)\n",
    "    mask = tf.concat([i for i in new_mask], axis=0)\n",
    "    single_input = tf.tile(single_input, [history.shape[0], 1, 1])\n",
    "    \n",
    "#     print(\"single_input: \", single_input.shape)\n",
    "#     print(\"history: \", history.shape)\n",
    "    scores = scoring(single_input, history)\n",
    "    new_mask = tf.expand_dims(mask, 1)#4，1，114\n",
    "    empty_mask = tf.tile(new_mask, [1, scores.shape[1], 1])#矩阵扩张 12，12，384，114\n",
    "    score = tf.cast(scores, tf.float32)\n",
    "    empty_mask = tf.cast(empty_mask, tf.float32)#4, 384, 114\n",
    "\n",
    "    score =  (score * empty_mask)#4, 384, 114\n",
    "    score = tf.unstack(score, axis=0)\n",
    "    n = len(score)\n",
    "    score = tf.concat([i for i in score], 0)\n",
    "    score.shape\n",
    "\n",
    "    alpha_flat = tf.nn.softmax(score, axis=1)\n",
    "    alpha_flat = tf.split(alpha_flat, n, axis=0)\n",
    "    alpha = tf.stack([i for i in alpha_flat], axis=0)\n",
    "\n",
    "    attended = tf.matmul(alpha, history)\n",
    "    tmp = tf.unstack(attended, axis=0)\n",
    "    n = len(tmp)\n",
    "    mean = tmp[0]\n",
    "    for i in range(1, n):\n",
    "        mean += tmp[i]\n",
    "    mean = tf.cast(mean, tf.float32)\n",
    "\n",
    "    # dim = list(map(float, history_qa_ids.shape))\n",
    "    attend = mean / n\n",
    "    new_input.append(attend)\n",
    "attend_tensor = tf.stack([i for i in new_input], axis=0)\n",
    "print(attend_tensor.shape)\n",
    "# sum(attend_tensor[0][0][0]) \n",
    "# attend_tensor\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run((tf.reduce_sum(attend_tensor))))\n",
    "    print(sess.run((tf.reduce_sum(input_tensor))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 114, 768])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = tf.concat([i for i in new_his], axis=0)\n",
    "history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x1, x2):\n",
    "\n",
    "        x1_rep = x1\n",
    "        x2_rep = x2\n",
    "\n",
    "        scores = x1_rep.matmul(x2_rep.transpose(2,1))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# a=torch.Tensor(2,3).uniform_(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 114, 768])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.rand([12,384,768])\n",
    "history_qa_ids = torch.ones([12,114,768])\n",
    "history_mask = torch.zeros([12,114])\n",
    "x3 = history_qa_ids\n",
    "history_qa_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 114, 768])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 384, 114])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = forward(input_tensor, history_qa_ids)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(CPUBoolType{[12, 1, 114, 768]}, size=[12, 384, 114]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-16963d092ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mempty_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# scores.data.masked_fill_(empty_mask.data, -float('inf'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0malpha_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_qa_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m114\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(CPUBoolType{[12, 1, 114, 768]}, size=[12, 384, 114]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "empty_mask = history_mask.eq(0).unsqueeze(1).expand_as(scores)\n",
    "# scores.data.masked_fill_(empty_mask.data, -float('inf'))\n",
    "alpha_flat = F.softmax(scores.view(12, -1, history_qa_ids.size(2)), dim = 2)\n",
    "alpha = alpha_flat.view(-1,12, 384, 114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 384, 114])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 57, 768])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.view(12, -1, history_qa_ids.size(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 57, 768]),\n",
       " torch.Size([1, 12, 384, 114]),\n",
       " torch.Size([12, 114, 768]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_flat.shape, alpha.shape, x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 384, 768])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attended = alpha.matmul(x3)\n",
    "attended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.1584e-02, 1.1584e-02, 1.1584e-02,  ..., 1.1584e-02,\n",
       "           1.1584e-02, 1.1584e-02],\n",
       "          [1.4302e-03, 1.4302e-03, 1.4302e-03,  ..., 1.4302e-03,\n",
       "           1.4302e-03, 1.4302e-03],\n",
       "          [8.1596e-07, 8.1596e-07, 8.1596e-07,  ..., 8.1596e-07,\n",
       "           8.1596e-07, 8.1596e-07],\n",
       "          ...,\n",
       "          [8.2477e-04, 8.2477e-04, 8.2477e-04,  ..., 8.2477e-04,\n",
       "           8.2477e-04, 8.2477e-04],\n",
       "          [3.5987e-06, 3.5987e-06, 3.5987e-06,  ..., 3.5987e-06,\n",
       "           3.5987e-06, 3.5987e-06],\n",
       "          [8.3319e-02, 8.3319e-02, 8.3319e-02,  ..., 8.3319e-02,\n",
       "           8.3319e-02, 8.3319e-02]],\n",
       "\n",
       "         [[2.9893e-06, 2.9893e-06, 2.9893e-06,  ..., 2.9893e-06,\n",
       "           2.9893e-06, 2.9893e-06],\n",
       "          [6.9360e-07, 6.9360e-07, 6.9360e-07,  ..., 6.9360e-07,\n",
       "           6.9360e-07, 6.9360e-07],\n",
       "          [1.8963e-09, 1.8963e-09, 1.8963e-09,  ..., 1.8963e-09,\n",
       "           1.8963e-09, 1.8963e-09],\n",
       "          ...,\n",
       "          [1.1989e-05, 1.1989e-05, 1.1989e-05,  ..., 1.1989e-05,\n",
       "           1.1989e-05, 1.1989e-05],\n",
       "          [9.0621e-12, 9.0621e-12, 9.0621e-12,  ..., 9.0621e-12,\n",
       "           9.0621e-12, 9.0621e-12],\n",
       "          [5.6270e-08, 5.6270e-08, 5.6270e-08,  ..., 5.6270e-08,\n",
       "           5.6270e-08, 5.6270e-08]],\n",
       "\n",
       "         [[8.3145e-01, 8.3145e-01, 8.3145e-01,  ..., 8.3145e-01,\n",
       "           8.3145e-01, 8.3145e-01],\n",
       "          [1.6811e-01, 1.6811e-01, 1.6811e-01,  ..., 1.6811e-01,\n",
       "           1.6811e-01, 1.6811e-01],\n",
       "          [1.8587e-06, 1.8587e-06, 1.8587e-06,  ..., 1.8587e-06,\n",
       "           1.8587e-06, 1.8587e-06],\n",
       "          ...,\n",
       "          [2.0539e-08, 2.0539e-08, 2.0539e-08,  ..., 2.0539e-08,\n",
       "           2.0539e-08, 2.0539e-08],\n",
       "          [3.1518e-05, 3.1518e-05, 3.1518e-05,  ..., 3.1518e-05,\n",
       "           3.1518e-05, 3.1518e-05],\n",
       "          [2.5541e-04, 2.5541e-04, 2.5541e-04,  ..., 2.5541e-04,\n",
       "           2.5541e-04, 2.5541e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.9064e-06, 1.9064e-06, 1.9064e-06,  ..., 1.9064e-06,\n",
       "           1.9064e-06, 1.9064e-06],\n",
       "          [8.7934e-01, 8.7934e-01, 8.7934e-01,  ..., 8.7934e-01,\n",
       "           8.7934e-01, 8.7934e-01],\n",
       "          [5.0695e-09, 5.0695e-09, 5.0695e-09,  ..., 5.0695e-09,\n",
       "           5.0695e-09, 5.0695e-09],\n",
       "          ...,\n",
       "          [3.0169e-05, 3.0169e-05, 3.0169e-05,  ..., 3.0169e-05,\n",
       "           3.0169e-05, 3.0169e-05],\n",
       "          [8.3238e-01, 8.3238e-01, 8.3238e-01,  ..., 8.3238e-01,\n",
       "           8.3238e-01, 8.3238e-01],\n",
       "          [7.9626e-04, 7.9626e-04, 7.9626e-04,  ..., 7.9626e-04,\n",
       "           7.9626e-04, 7.9626e-04]],\n",
       "\n",
       "         [[3.4861e-12, 3.4861e-12, 3.4861e-12,  ..., 3.4861e-12,\n",
       "           3.4861e-12, 3.4861e-12],\n",
       "          [9.8337e-01, 9.8337e-01, 9.8337e-01,  ..., 9.8337e-01,\n",
       "           9.8337e-01, 9.8337e-01],\n",
       "          [1.9776e-08, 1.9776e-08, 1.9776e-08,  ..., 1.9776e-08,\n",
       "           1.9776e-08, 1.9776e-08],\n",
       "          ...,\n",
       "          [2.1801e-11, 2.1801e-11, 2.1801e-11,  ..., 2.1801e-11,\n",
       "           2.1801e-11, 2.1801e-11],\n",
       "          [1.5075e-05, 1.5075e-05, 1.5075e-05,  ..., 1.5075e-05,\n",
       "           1.5075e-05, 1.5075e-05],\n",
       "          [9.9252e-01, 9.9252e-01, 9.9252e-01,  ..., 9.9252e-01,\n",
       "           9.9252e-01, 9.9252e-01]],\n",
       "\n",
       "         [[8.9207e-01, 8.9207e-01, 8.9207e-01,  ..., 8.9207e-01,\n",
       "           8.9207e-01, 8.9207e-01],\n",
       "          [1.1397e-07, 1.1397e-07, 1.1397e-07,  ..., 1.1397e-07,\n",
       "           1.1397e-07, 1.1397e-07],\n",
       "          [6.9045e-17, 6.9045e-17, 6.9045e-17,  ..., 6.9045e-17,\n",
       "           6.9045e-17, 6.9045e-17],\n",
       "          ...,\n",
       "          [8.8348e-01, 8.8348e-01, 8.8348e-01,  ..., 8.8348e-01,\n",
       "           8.8348e-01, 8.8348e-01],\n",
       "          [1.3149e-10, 1.3149e-10, 1.3149e-10,  ..., 1.3149e-10,\n",
       "           1.3149e-10, 1.3149e-10],\n",
       "          [1.0290e-08, 1.0290e-08, 1.0290e-08,  ..., 1.0290e-08,\n",
       "           1.0290e-08, 1.0290e-08]]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(x1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.8967)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(attended[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([12,384,768])\n",
    "x2 = torch.rand([12,12,114,768])\n",
    "x2_mask = torch.rand([12,12,114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = x2\n",
    "x = torch.zeros([12,12,384,768])\n",
    "x1 = x1.unsqueeze(1).expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_rep = x1\n",
    "x2_rep = x2\n",
    "scores = x1_rep.matmul(x2_rep.transpose(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "empty_mask = x2_mask.eq(0).unsqueeze(2).expand_as(scores)\n",
    "scores.data.masked_fill_(empty_mask.data, -float('inf'))\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_flat = F.softmax(scores.view(-1, x2.size(1)), dim = 1)\n",
    "alpha = alpha_flat.view(-1, x1.size(1), x2.size(1))\n",
    "alpha_flat.shape, alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attended = alpha.bmm(x3)\n",
    "attended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attended = alpha.matmul(x3)\n",
    "attended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(x1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(attended[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 384, 768])"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand([384,768])\n",
    "x = x.expand([12,-1,-1])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new(x1, x2):\n",
    "\n",
    "        x1_rep = x1\n",
    "        x2_rep = x2\n",
    "\n",
    "        scores = x1_rep.matmul(x2_rep.transpose(2,1))\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand([12,384,768])\n",
    "b = torch.rand([12,64,768])\n",
    "c = torch.zeros([12,208,768])\n",
    "# b = a\n",
    "d = torch.cat([b,c], axis=1)\n",
    "# c = torch.ones([12,50]).bool()\n",
    "t1 = torch.ones([12,64])\n",
    "t2 = torch.zeros([12,208])\n",
    "mask = torch.cat([t1,t2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 384, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = new(a, d)\n",
    "empty_mask = mask.eq(0).unsqueeze(1).expand_as(scores)\n",
    "scores.data.masked_fill_(empty_mask.data, -float('inf'))\n",
    "alpha_flat = F.softmax(scores.view(-1, d.size(1)), dim = 1)\n",
    "alpha = alpha_flat.view(-1, 384, 272)\n",
    "attended = alpha.matmul(d)\n",
    "attended.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 100, 50])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3005e-01, 8.1368e-01, 6.3015e-01,  ..., 6.0221e-01,\n",
       "          9.4395e-01, 8.1164e-01],\n",
       "         [5.8506e-01, 7.9978e-01, 7.4815e-01,  ..., 5.0843e-01,\n",
       "          8.7747e-01, 2.7704e-01],\n",
       "         [1.3238e-01, 5.1905e-01, 7.1893e-02,  ..., 5.0848e-01,\n",
       "          1.1791e-01, 5.0154e-02],\n",
       "         ...,\n",
       "         [6.2830e-01, 4.8316e-02, 4.4810e-01,  ..., 6.4548e-02,\n",
       "          2.5952e-01, 6.6925e-02],\n",
       "         [9.2278e-01, 5.7031e-01, 5.0595e-01,  ..., 5.3350e-01,\n",
       "          9.3800e-01, 2.8004e-01],\n",
       "         [3.6305e-01, 5.8494e-01, 5.4665e-01,  ..., 1.6257e-01,\n",
       "          5.6919e-01, 7.9708e-01]],\n",
       "\n",
       "        [[2.7301e-02, 3.0565e-01, 3.8107e-01,  ..., 7.2160e-01,\n",
       "          7.4898e-01, 7.3716e-01],\n",
       "         [4.1308e-01, 2.7185e-01, 6.2480e-01,  ..., 5.1992e-01,\n",
       "          7.1710e-01, 2.6360e-01],\n",
       "         [8.9103e-01, 1.0473e-01, 3.2865e-01,  ..., 1.0153e-01,\n",
       "          4.6308e-02, 8.6007e-01],\n",
       "         ...,\n",
       "         [4.2556e-01, 8.2972e-01, 6.9587e-01,  ..., 9.2039e-02,\n",
       "          1.0892e-01, 8.5221e-01],\n",
       "         [9.8788e-01, 5.3649e-01, 5.8650e-01,  ..., 4.0215e-01,\n",
       "          4.4778e-02, 6.0212e-01],\n",
       "         [3.8628e-01, 3.7371e-01, 4.9594e-01,  ..., 4.0317e-01,\n",
       "          5.4690e-02, 9.5982e-01]],\n",
       "\n",
       "        [[4.0492e-02, 3.4170e-01, 9.0162e-02,  ..., 8.5532e-01,\n",
       "          1.5593e-01, 4.3377e-01],\n",
       "         [5.8356e-01, 1.2062e-01, 9.4073e-01,  ..., 1.3141e-01,\n",
       "          1.9079e-01, 3.2311e-02],\n",
       "         [9.3353e-01, 2.9500e-01, 1.3001e-01,  ..., 4.4569e-01,\n",
       "          5.6807e-01, 6.3616e-01],\n",
       "         ...,\n",
       "         [6.0939e-01, 8.4754e-02, 5.8668e-01,  ..., 6.3200e-01,\n",
       "          3.2963e-01, 2.7788e-01],\n",
       "         [8.7997e-01, 5.7833e-01, 6.4318e-01,  ..., 5.0660e-01,\n",
       "          4.4317e-01, 9.4268e-01],\n",
       "         [7.2659e-01, 5.6527e-01, 9.4205e-01,  ..., 7.8594e-01,\n",
       "          9.1358e-01, 9.8837e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.0278e-01, 5.6842e-01, 4.5367e-01,  ..., 7.9365e-01,\n",
       "          9.6341e-01, 7.5446e-01],\n",
       "         [6.9282e-02, 7.7715e-01, 4.8712e-01,  ..., 2.1732e-02,\n",
       "          1.9676e-01, 3.0874e-01],\n",
       "         [4.9612e-01, 5.8820e-01, 9.7397e-02,  ..., 1.1684e-01,\n",
       "          8.0138e-01, 1.6298e-01],\n",
       "         ...,\n",
       "         [5.2018e-01, 2.2554e-01, 5.8018e-01,  ..., 5.9621e-01,\n",
       "          9.2787e-04, 4.5617e-01],\n",
       "         [8.2187e-01, 2.4857e-01, 1.2644e-01,  ..., 7.8030e-01,\n",
       "          6.3244e-02, 2.4490e-01],\n",
       "         [3.7633e-01, 4.3742e-01, 4.2596e-01,  ..., 6.3789e-01,\n",
       "          8.6619e-02, 5.8311e-01]],\n",
       "\n",
       "        [[3.0099e-01, 7.8502e-01, 5.6256e-01,  ..., 1.2129e-01,\n",
       "          9.0404e-01, 1.5543e-01],\n",
       "         [7.0783e-01, 1.3117e-01, 3.9766e-01,  ..., 6.3067e-01,\n",
       "          3.4924e-01, 5.6260e-01],\n",
       "         [1.4169e-01, 1.9585e-01, 7.2474e-01,  ..., 7.0486e-01,\n",
       "          9.1457e-01, 4.6279e-02],\n",
       "         ...,\n",
       "         [9.4911e-02, 7.8498e-01, 3.8749e-01,  ..., 5.0031e-01,\n",
       "          5.3213e-01, 4.1658e-01],\n",
       "         [2.0886e-01, 3.5793e-01, 9.4999e-01,  ..., 8.5819e-01,\n",
       "          1.7151e-01, 5.0658e-01],\n",
       "         [7.1711e-01, 8.5745e-01, 4.1023e-01,  ..., 5.5838e-01,\n",
       "          8.7891e-01, 9.7908e-01]],\n",
       "\n",
       "        [[7.3691e-01, 8.1997e-01, 9.3187e-01,  ..., 6.3918e-01,\n",
       "          2.7807e-02, 8.6891e-01],\n",
       "         [6.0900e-01, 4.1451e-01, 4.2971e-01,  ..., 9.8619e-01,\n",
       "          8.9401e-02, 9.2847e-01],\n",
       "         [3.9006e-01, 7.0093e-01, 8.1228e-01,  ..., 4.1440e-01,\n",
       "          2.5994e-01, 1.3156e-01],\n",
       "         ...,\n",
       "         [7.9864e-01, 5.7358e-01, 1.7077e-01,  ..., 3.4730e-01,\n",
       "          4.6553e-01, 1.3716e-01],\n",
       "         [1.4983e-02, 3.0716e-01, 9.2268e-01,  ..., 6.9467e-01,\n",
       "          3.8341e-01, 2.8257e-01],\n",
       "         [1.5536e-01, 9.5134e-01, 6.1174e-01,  ..., 5.0695e-01,\n",
       "          5.2210e-01, 8.6241e-01]]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = torch.rand([12,114,768])\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.zeros([1,384,384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "attend = torch.matmul(alpha, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384, 768])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_808:0' shape=(12,) dtype=int32>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([12,4,5,6,7,9,6,3,2,4,6,7])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.split(a, 12, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'split_782:0' shape=(1,) dtype=int32>"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 4\n",
    "tmp = tf.zeros([4,114,768])\n",
    "lists = []\n",
    "lists.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hongshibo/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "v2=tf.Variable(tf.constant(2),name='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def func(fn, tensor):\n",
    "  return tf.map_fn(fn, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-480-f326715de8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mxxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msquares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m114\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# squares == [1, 4, 9, 16, 25, 36]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msquares\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    205\u001b[0m         ops.convert_to_tensor(elem, name=\"elem\") for elem in elems_flat]\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_flat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mdtype_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    513\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    514\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# elems = np.array([1, 2, 3, 4, 5, 6])\n",
    "elems = tf.constant([1,2,3,4,5], dtype=tf.int32)\n",
    "tmp = tf.zeros([12, 12,114], dtype=tf.int32)\n",
    "# tf.slice(tmp, [0,0,0],[1, 114,768])\n",
    "du = tf.map_fn(lambda x: x*x, elems, dtype=tf.int32)\n",
    "xxx = tf.constant([1,2,3,4,5])\n",
    "# squares = tf.map_fn(lambda x, y: tf.slice(tmp, [y-1,0,0],[1, x, 114]), elems,xxx)\n",
    "squares = func()\n",
    "# squares == [1, 4, 9, 16, 25, 36]\n",
    "squares.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tf.unstack(squares, 12, axis=0)\n",
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([384, 114])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([12,384,114])\n",
    "a = tf.reduce_mean(a, axis=0)\n",
    "tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument 'Tensor(\"Shape:0\", shape=(2,), dtype=int32)' cannot be interpreted as a Tensor. (The name 'Tensor(\"Shape:0\", shape=(2,), dtype=int32)' looks a like a Tensor name, but is not a valid one. Tensor names must be of the form \"<op_name>:<output_index>\".)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3536\u001b[0m           \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3537\u001b[0;31m           \u001b[0mout_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3538\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '0\", shape=(2,), dtype=int32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 305\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3540\u001b[0m                            \u001b[0;34m\"not a valid one. Tensor names must be of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3541\u001b[0;31m                            \"form \\\"<op_name>:<output_index>\\\".\" % repr(name))\n\u001b[0m\u001b[1;32m   3542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mop_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The name 'Tensor(\"Shape:0\", shape=(2,), dtype=int32)' looks a like a Tensor name, but is not a valid one. Tensor names must be of the form \"<op_name>:<output_index>\".",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-451-a63929b11e16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 960\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    961\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1168\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 312\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    313\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument 'Tensor(\"Shape:0\", shape=(2,), dtype=int32)' cannot be interpreted as a Tensor. (The name 'Tensor(\"Shape:0\", shape=(2,), dtype=int32)' looks a like a Tensor name, but is not a valid one. Tensor names must be of the form \"<op_name>:<output_index>\".)"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run(str(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'unstack_401:0' shape=(1, None, 114, 768) dtype=float32>"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tf.unstack(squares, 12, axis=0)\n",
    "# new = tf.split(squares, 12, axis=0)\n",
    "\n",
    "new = new[0]\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Squeeze_5716:0' shape=(None, 114, 768) dtype=float32>"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(new, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists.pop(-1)\n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-468-20c6e1f6f8ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m114\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m114\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "a = tf.ones([12,384,114])\n",
    "b= tf.reshape(a, [-1,114])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.framework.ops.Tensor,\n",
       " tensorflow.python.framework.ops.Tensor)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tf.zeros([12,12,114], dtype=tf.int32)\n",
    "TensorArr = tf.TensorArray(tf.int32, 1, dynamic_size=True, infer_shape=False)\n",
    "x = TensorArr.unstack(tmp)\n",
    "type(x.read(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def fun(tmp, tmp2, lis):\n",
    "    new = []\n",
    "    for t in tmp2:\n",
    "        new.append(tf.slice(tmp, [0,0], [t,tmp.shape[1]]))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InaccessibleTensorError",
     "evalue": "The tensor 'Tensor(\"Slice:0\", shape=(None, 114), dtype=int32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_913617, id=6478056272); accessed from: FuncGraph(name=fun, id=6345570192).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInaccessibleTensorError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-493-8e1d15c62b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 497\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    981\u001b[0m       \u001b[0;31m# TensorArrays and `None`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       func_outputs = nest.map_structure(convert, func_outputs,\n\u001b[0;32m--> 983\u001b[0;31m                                         expand_composites=True)\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0mcheck_mutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_args_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    943\u001b[0m               (str(python_func), type(x)))\n\u001b[1;32m    944\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeps_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36mmark_as_return\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# of a new identity operation that the stateful operations definitely don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# depend on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_returned_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3827\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 3829\u001b[0;31m         \"Identity\", input=input, name=name)\n\u001b[0m\u001b[1;32m   3830\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mctxt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AddValue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    639\u001b[0m               \u001b[0;34m\" explicit Python locals or TensorFlow collections to access\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m               \u001b[0;34m\" it. Defined in: %s; accessed from: %s.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m               % (tensor, tensor.graph, self))\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0minner_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInaccessibleTensorError\u001b[0m: The tensor 'Tensor(\"Slice:0\", shape=(None, 114), dtype=int32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_913617, id=6478056272); accessed from: FuncGraph(name=fun, id=6345570192).\n"
     ]
    }
   ],
   "source": [
    "tmp = tf.zeros([12,114], dtype=tf.int32)\n",
    "tmp2 = tf.constant([2,1,0,4,1])\n",
    "lis = []\n",
    "new = fun(tmp, tmp2, lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-517-c9bd109bbece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0melems1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0melems2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    205\u001b[0m         ops.convert_to_tensor(elem, name=\"elem\") for elem in elems_flat]\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_flat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mdtype_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    513\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    514\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "history_output = tf.zeros([12,12,114,768])\n",
    "\n",
    "fn = lambda x, y: tf.slice(history_output, [x,0,0,0],[1, y, 114, 768])\n",
    "\n",
    "elems1 = tf.constant([1,2,3,4,3,5,6,7,3,2,1,4])\n",
    "elems2 = tf.constant([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "history_list = tf.unstack(tf.map_fn(fn, elems1, elems2), 12, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nums = [list(range(i * 10, (i + 1) * 10)) + [0] for i in range(1, 5)]\n",
    "matrix = tf.constant(nums)\n",
    "X = tf.constant(36, dtype=matrix.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = tf.zeros([1, 4, 114], dtype=tf.float32)\n",
    "b = tf.ones([1, 8, 114],dtype=tf.float32)\n",
    "c = tf.concat([b, a], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-545-6c5ad6c40b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     result = tf.cond(t > y, tf.reduce_mean(t), tf.reduce_mean(compare))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m       \u001b[0;31m# Default: V1-style Graph execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    513\u001b[0m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[1;32m    514\u001b[0m         \u001b[0;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \" this function with @tf.function.\".format(task))\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_bool_casting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "tmp = tf.unstack(c, axis=1)\n",
    "fn = lambda x : x\n",
    "compare = tf.zeros([1, 1, 114], dtype=tf.float32)\n",
    "lists = []\n",
    "for t in tmp:\n",
    "    x = tf.reduce_mean(t)\n",
    "    if x>0:\n",
    "        lists.append(t)\n",
    "#     result = tf.cond(t > y, tf.reduce_mean(t), tf.reduce_mean(compare))\n",
    "#     print(result)\n",
    "        \n",
    "\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     for t in tmp:\n",
    "#         x = tf.reduce_mean(t)\n",
    "#         print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zeroes = tf.zeros([600, 1], dtype=tf.float32)\n",
    "ones = tf.ones([600, 1], dtype=tf.float32)\n",
    "b = tf.random.uniform([600,10], minval=0, maxval=1, dtype=tf.float32)\n",
    "threshold = tf.constant(0., dtype=tf.float32)\n",
    "\n",
    "check = tf.reduce_max(tf.cast(b > threshold, dtype=tf.float32), axis=1)\n",
    "last_col = tf.where(check>0, zeroes, ones)\n",
    "# new_b = tf.where(check>0, b, tf.zeros([600, 10], dtype=tf.float32))\n",
    "# new_matrix = tf.concat([new_b, last_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([600]), TensorShape([600, 600]))"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape, last_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([600, 10])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(i):\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to capture an EagerTensor without building a function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c5333fa388ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     arr2 = tf.constant([[False, True],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#                         [True, False]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mboolean_mask_v2\u001b[0;34m(tensor, mask, axis, name)\u001b[0m\n\u001b[1;32m   1655\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m   \"\"\"\n\u001b[0;32m-> 1657\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mboolean_mask\u001b[0;34m(tensor, mask, name, axis)\u001b[0m\n\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1278\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[0m\u001b[1;32m   1281\u001b[0m                            \"building a function.\")\n\u001b[1;32m   1282\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to capture an EagerTensor without building a function."
     ]
    }
   ],
   "source": [
    "a = tf.zeros([1, 4, 114], dtype=tf.int32)\n",
    "b = tf.ones([1, 8, 114], dtype=tf.int32)\n",
    "c = tf.concat([b, a], axis=1)\n",
    "d = tf.constant([1,1,1,1,1,1,1,1,0,0,0,0])\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "#     arr1 = tf.constant([[1,2],\n",
    "#                         [3,4]])\n",
    "#     arr2 = tf.constant([[False, True],\n",
    "#                         [True, False]])\n",
    "    print(sess.run(tf.boolean_mask(c, d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12, 114), dtype=int32, numpy=\n",
       "array([[[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.zeros([1, 4, 114], dtype=tf.int32)\n",
    "b = tf.ones([1, 8, 114], dtype=tf.int32)\n",
    "c = tf.concat([b, a], axis=1)\n",
    "d = tf.constant([1,1,1,1,1,1,1,1,0,0,0,0])\n",
    "# e = tf.zeros([1, 114], dtype=tf.int32)\n",
    "# tmp = tf.unstack(c, axis=1)\n",
    "# threshold = tf.constant(0, dtype=tf.int32)\n",
    "# l = []\n",
    "# s = []\n",
    "\n",
    "# for i in tmp:\n",
    "#     new = tf.reduce_max(i)\n",
    "#     greater = tf.greater(new, threshold)\n",
    "#     x = tf.cond(tf.equal(greater, tf.constant(True)), lambda : tf.concat([e,i],0), lambda : func(e))\n",
    "# #     print(x.shape(0))\n",
    "#     print(x)\n",
    "d = tf.expand_dims(d,axis=0)\n",
    "# tf.split(c,d,0)\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cond_15/Identity:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "a = tf.compat.v1.placeholder(tf.bool)  #placeholder for a single boolean value\n",
    "b = tf.cond(tf.equal(a, tf.constant(True)), lambda: tf.constant(10), lambda: tf.constant(0))\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "res = sess.run(b, feed_dict = {a: True})\n",
    "sess.close()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.zeros([1,12,114])\n",
    "len(tf.unstack(a, 12, axis=1)[:turn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = tf.zeros([1,114,768])\n",
    "mask = tf.zeros([1,114])\n",
    "scores = tf.zeros([1,384,114])#1 * 384 * 114\n",
    "num = tf.shape(scores)[1]\n",
    "# empty_mask = history_mask.eq(0).unsqueeze(1).expand_as(scores)\n",
    "history_mask = tf.expand_dims(mask, 1)#1，1，114\n",
    "empty_mask = tf.tile(history_mask, [1, num, 1])#矩阵扩张 12，12，384，114\n",
    "score = tf.cast(scores, tf.float32)\n",
    "empty_mask = tf.cast(empty_mask, tf.float32)\n",
    "\n",
    "score =  (score * empty_mask)\n",
    "\n",
    "# softmax\n",
    "# alpha = alpha_flat.view(-1, input_tensor.size(1), history_qa_ids.size(1))\n",
    "alpha_flat = tf.nn.softmax(score, axis=2)\n",
    "# alpha_flat = tf.split(alpha_flat, n, axis=0)\n",
    "# alpha = tf.stack([i for i in alpha_flat], axis=0)\n",
    "\n",
    "# alpha: batch x word_num1 x word_num2\n",
    "attended = tf.matmul(alpha_flat, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 384, 768])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = tf.zeros(tf.shape(attended), dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(384, 768), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(mean, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = [101, 2339, 2106, 2002, 2689, 2010, 2490, 2000, 2068, 1029, 102, 17251, 13198, 2031, 2036, 4427, 2195, 4684, 5097, 2005, 16380, 1998, 11924, 1012, 4401, 1010, 2107, 2004, 16480, 14115, 26760, 24079, 1010, 2031, 7034, 2008, 11948, 5498, 9126, 2705, 2038, 1996, 4022, 2000, 2022, 3144, 1999, 2796, 4331, 2349, 2000, 2010, 6217, 1998, 5470, 2918, 2894, 1012, 1999, 2786, 1010, 11948, 5498, 9126, 2705, 2211, 4637, 1996, 2796, 2120, 3519, 2044, 3116, 3539, 2704, 1052, 1012, 1058, 1012, 27544, 5332, 2213, 3270, 10546, 1012, 2019, 5448, 8554, 4146, 2011, 1996, 2932, 13970, 12274, 17130, 10173, 2008, 3519, 1010, 2007, 11948, 5498, 9126, 2705, 1005, 1055, 2490, 1010, 2453, 2663, 2039, 2000, 7558, 4272, 1999, 1996, 6008, 10703, 3320, 1012, 1999, 2727, 1010, 2043, 1996, 3519, 2283, 2787, 2000, 25705, 2007, 2035, 2634, 4698, 2852, 18891, 2850, 14163, 10087, 6494, 10556, 27922, 16098, 2213, 1006, 9932, 4215, 2213, 2243, 1007, 2005, 1996, 3320, 2602, 1999, 6008, 10703, 1010, 11948, 5498, 9126, 2705, 2904, 8884, 7368, 1998, 3569, 1996, 2852, 18891, 2850, 14163, 10087, 6494, 10556, 27922, 16098, 2213, 1006, 1040, 2213, 2243, 1007, 1011, 6008, 5003, 7088, 2721, 3519, 1006, 1056, 12458, 1007, 4707, 1012, 1996, 1056, 12458, 2109, 1037, 10165, 2004, 2037, 2602, 6454, 1998, 2109, 2019, 3746, 1997, 11948, 5498, 9126, 2705, 5559, 1037, 10165, 2013, 1996, 2143, 4698, 9067, 4886, 1999, 2037, 14921, 1012, 11948, 5498, 9126, 2705, 2056, 1024, 1000, 2130, 2643, 3685, 3828, 6008, 10703, 2065, 9932, 4215, 2213, 2243, 5651, 2000, 2373, 1012, 1000, 11948, 5498, 9126, 2705, 2878, 27693, 2135, 3569, 1996, 1040, 2213, 2243, 1998, 1056, 12458, 4707, 1998, 2356, 1996, 2111, 1997, 6008, 10703, 1998, 2010, 4599, 2000, 3789, 2005, 2008, 4707, 1012, 2023, 4707, 2018, 1037, 3143, 3377, 1999, 2727, 1012, 11948, 5498, 9126, 2705, 2036, 3569, 1996, 1040, 2213, 2243, 1011, 1056, 12458, 4707, 1999, 1996, 5768, 2602, 1010, 2218, 1996, 2168, 2095, 1012, 2101, 1999, 2432, 1010, 11948, 5498, 9126, 2705, 2056, 2002, 2052, 7714, 3789, 2005, 1996, 24243, 20308, 2283, 1006, 24954, 1007, 2021, 2052, 2025, 7949, 2010, 2490, 2000, 2151, 2392, 2076, 1996, 9046, 2796, 2236, 2602, 1012, 1996, 2283, 1010, 2174, 1010, 3478, 2000, 2663, 2151, 4272, 1999, 6008, 10703, 1999, 1996, 13660, 11200, 1012, 4599, 1997, 11948, 5498, 9126, 2705, 1999, 6008, 10703, 2031, 10843, 15520, 2006, 102]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_id = pd.DataFrame(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.nn import functional \n",
    "embedding_table = Variable(torch.randn([32000, 128],dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5388, -0.0370, -0.2933,  ...,  0.6444,  1.4417,  1.3879],\n",
       "        [-0.2459,  1.2643,  0.1578,  ...,  0.2839, -0.7094, -1.2146],\n",
       "        [-1.2718,  1.3095,  1.0598,  ..., -0.3237,  0.1601, -0.1534],\n",
       "        ...,\n",
       "        [ 0.2182,  0.6415,  0.0186,  ...,  0.8556,  0.5961, -0.0383],\n",
       "        [-0.6343,  2.8066, -2.1052,  ...,  0.1330, -0.8524,  1.2732],\n",
       "        [ 0.1418, -0.6734,  0.0218,  ..., -1.3258, -1.3943, -0.9412]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initializer(initializer_range=0.02):\n",
    "  \"\"\"Creates a `truncated_normal_initializer` with the given range.\"\"\"\n",
    "  return tf.compat.v1.truncated_normal_initializer(stddev=initializer_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_table = tf.compat.v1.get_variable(\n",
    "      name='word_embedding_name',\n",
    "      shape=[32000, 128],\n",
    "      initializer=create_initializer(0.02),\n",
    "      dtype=tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find valid device for node.\nNode:{{node OneHot}}\nAll kernels registered for op OneHot :\n  device='XLA_CPU_JIT'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_CPU'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT32]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT64]; T in [DT_STRING]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_VARIANT]\n [Op:OneHot] name: one_hot/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-8930e2f16b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflat_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mone_hot_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# output = tf.matmul(one_hot_input_ids, embedding_table)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m   3643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3644\u001b[0m     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\n\u001b[0;32m-> 3645\u001b[0;31m                                  name)\n\u001b[0m\u001b[1;32m   3646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Could not find valid device for node.\nNode:{{node OneHot}}\nAll kernels registered for op OneHot :\n  device='XLA_CPU_JIT'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_CPU'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT32]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT64]; T in [DT_STRING]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_VARIANT]\n [Op:OneHot] name: one_hot/"
     ]
    }
   ],
   "source": [
    "flat_input_ids = tf.reshape(input_ids, [-1])\n",
    "one_hot_input_ids = tf.one_hot(flat_input_ids, depth=32000)\n",
    "# output = tf.matmul(one_hot_input_ids, embedding_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-8d0d7c19fe14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# input_ids = torch.tensor([])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mflat_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mone_hot_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "# input_ids = torch.ones([384])\n",
    "# input_ids = torch.tensor([])\n",
    "flat_input_ids = torch.reshape(input_ids, [-1])\n",
    "one_hot_input_ids = functional.one_hot(flat_input_ids, num_classes=32000)\n",
    "output = torch.matmul(one_hot_input_ids, embedding_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "lis = [101, 2339, 2106, 2002, 2689, 2010, 2490, 2000, 2068, 1029, 102, 17251, 13198, 2031, 2036, 4427, 2195, 4684, 5097, 2005, 16380, 1998, 11924, 1012, 4401, 1010, 2107, 2004, 16480, 14115, 26760, 24079, 1010, 2031, 7034, 2008, 11948, 5498, 9126, 2705, 2038, 1996, 4022, 2000, 2022, 3144, 1999, 2796, 4331, 2349, 2000, 2010, 6217, 1998, 5470, 2918, 2894, 1012, 1999, 2786, 1010, 11948, 5498, 9126, 2705, 2211, 4637, 1996, 2796, 2120, 3519, 2044, 3116, 3539, 2704, 1052, 1012, 1058, 1012, 27544, 5332, 2213, 3270, 10546, 1012, 2019, 5448, 8554, 4146, 2011, 1996, 2932, 13970, 12274, 17130, 10173, 2008, 3519, 1010, 2007, 11948, 5498, 9126, 2705, 1005, 1055, 2490, 1010, 2453, 2663, 2039, 2000, 7558, 4272, 1999, 1996, 6008, 10703, 3320, 1012, 1999, 2727, 1010, 2043, 1996, 3519, 2283, 2787, 2000, 25705, 2007, 2035, 2634, 4698, 2852, 18891, 2850, 14163, 10087, 6494, 10556, 27922, 16098, 2213, 1006, 9932, 4215, 2213, 2243, 1007, 2005, 1996, 3320, 2602, 1999, 6008, 10703, 1010, 11948, 5498, 9126, 2705, 2904, 8884, 7368, 1998, 3569, 1996, 2852, 18891, 2850, 14163, 10087, 6494, 10556, 27922, 16098, 2213, 1006, 1040, 2213, 2243, 1007, 1011, 6008, 5003, 7088, 2721, 3519, 1006, 1056, 12458, 1007, 4707, 1012, 1996, 1056, 12458, 2109, 1037, 10165, 2004, 2037, 2602, 6454, 1998, 2109, 2019, 3746, 1997, 11948, 5498, 9126, 2705, 5559, 1037, 10165, 2013, 1996, 2143, 4698, 9067, 4886, 1999, 2037, 14921, 1012, 11948, 5498, 9126, 2705, 2056, 1024, 1000, 2130, 2643, 3685, 3828, 6008, 10703, 2065, 9932, 4215, 2213, 2243, 5651, 2000, 2373, 1012, 1000, 11948, 5498, 9126, 2705, 2878, 27693, 2135, 3569, 1996, 1040, 2213, 2243, 1998, 1056, 12458, 4707, 1998, 2356, 1996, 2111, 1997, 6008, 10703, 1998, 2010, 4599, 2000, 3789, 2005, 2008, 4707, 1012, 2023, 4707, 2018, 1037, 3143, 3377, 1999, 2727, 1012, 11948, 5498, 9126, 2705, 2036, 3569, 1996, 1040, 2213, 2243, 1011, 1056, 12458, 4707, 1999, 1996, 5768, 2602, 1010, 2218, 1996, 2168, 2095, 1012, 2101, 1999, 2432, 1010, 11948, 5498, 9126, 2705, 2056, 2002, 2052, 7714, 3789, 2005, 1996, 24243, 20308, 2283, 1006, 24954, 1007, 2021, 2052, 2025, 7949, 2010, 2490, 2000, 2151, 2392, 2076, 1996, 9046, 2796, 2236, 2602, 1012, 1996, 2283, 1010, 2174, 1010, 3478, 2000, 2663, 2151, 4272, 1999, 6008, 10703, 1999, 1996, 13660, 11200, 1012, 4599, 1997, 11948, 5498, 9126, 2705, 1999, 6008, 10703, 2031, 10843, 15520, 2006, 102]\n",
    "print(len(lis))\n",
    "input_id= tf.constant(lis,dtype=tf.float64)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id=[101.6, 2339, 2106, 2002, 2689, 2010, 2490, 2000, 2068, 1029, 102, 17251, 13198, 2031, 2036, 4427, 2195, 4684, 5097, 2005, 16380, 1998, 11924, 1012, 4401, 1010, 2107, 2004, 16480, 14115, 26760, 24079, 1010, 2031, 7034, 2008, 11948, 5498, 9126, 2705, 2038, 1996, 4022, 2000, 2022, 3144, 1999, 2796, 4331, 2349, 2000, 2010, 6217, 1998, 5470, 2918, 2894, 1012, 1999, 2786, 1010, 11948, 5498, 9126, 2705, 2211, 4637, 1996, 2796, 2120, 3519, 2044, 3116, 3539, 2704, 1052, 1012, 1058, 1012, 27544, 5332, 2213, 3270, 10546, 1012, 2019, 5448, 8554, 4146, 2011, 1996, 2932, 13970, 12274, 17130, 10173, 2008, 3519, 1010, 2007, 11948, 5498, 9126, 2705, 1005, 1055, 2490, 1010, 2453, 2663, 2039, 2000, 7558, 4272, 1999, 1996, 6008, 10703, 3320, 1012, 1999, 2727, 1010, 2043, 1996, 3519, 2283, 2787, 2000, 25705, 2007, 2035, 2634, 4698, 2852, 18891, 2850, 14163, 10087, 6494, 10556, 27922, 16098, 2213, 1006, 9932, 4215, 2213, 2243, 1007, 2005, 1996, 3320, 2602, 1999, 6008, 10703, 1010, 11948, 5498, 9126, 2705, 2904, 8884, 7368, 1998, 3569, 1996, 2852, 18891, 2850, 14163, 10087, 6494, 10556, 27922, 16098, 2213, 1006, 1040, 2213, 2243, 1007, 1011, 6008, 5003, 7088, 2721, 3519, 1006, 1056, 12458, 1007, 4707, 1012, 1996, 1056, 12458, 2109, 1037, 10165, 2004, 2037, 2602, 6454, 1998, 2109, 2019, 3746, 1997, 11948, 5498, 9126, 2705, 5559, 1037, 10165, 2013, 1996, 2143, 4698, 9067, 4886, 1999, 2037, 14921, 1012, 11948, 5498, 9126, 2705, 2056, 1024, 1000, 2130, 2643, 3685, 3828, 6008, 10703, 2065, 9932, 4215, 2213, 2243, 5651, 2000, 2373, 1012, 1000, 11948, 5498, 9126, 2705, 2878, 27693, 2135, 3569, 1996, 1040, 2213, 2243, 1998, 1056, 12458, 4707, 1998, 2356, 1996, 2111, 1997, 6008, 10703, 1998, 2010, 4599, 2000, 3789, 2005, 2008, 4707, 1012, 2023, 4707, 2018, 1037, 3143, 3377, 1999, 2727, 1012, 11948, 5498, 9126, 2705, 2036, 3569, 1996, 1040, 2213, 2243, 1011, 1056, 12458, 4707, 1999, 1996, 5768, 2602, 1010, 2218, 1996, 2168, 2095, 1012, 2101, 1999, 2432, 1010, 11948, 5498, 9126, 2705, 2056, 2002, 2052, 7714, 3789, 2005, 1996, 24243, 20308, 2283, 1006, 24954, 1007, 2021, 2052, 2025, 7949, 2010, 2490, 2000, 2151, 2392, 2076, 1996, 9046, 2796, 2236, 2602, 1012, 1996, 2283, 1010, 2174, 1010, 3478, 2000, 2663, 2151, 4272, 1999, 6008, 10703, 1999, 1996, 13660, 11200, 1012, 4599, 1997, 11948, 5498, 9126, 2705, 1999, 6008, 10703, 2031, 10843, 15520, 2006, 102]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "# layernorm = tf.keras.layers.LayerNormalization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-68b2c3f3a535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'Tensor'"
     ]
    }
   ],
   "source": [
    "tmp= tf.convert_to_tensor(input_id, dtype=tf.float32)\n",
    "int(tmp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(tmp.numpy())\n",
    "type(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n"
     ]
    }
   ],
   "source": [
    "lists = [2,2,3,4,5,6]\n",
    "for i, l in enumerate(lists):\n",
    "    print(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  2339  2106  2002  2689  2010  2490  2000  2068  1029   102 17251\n",
      " 13198  2031  2036  4427  2195  4684  5097  2005 16380  1998 11924  1012\n",
      "  4401  1010  2107  2004 16480 14115 26760 24079  1010  2031  7034  2008\n",
      " 11948  5498  9126  2705  2038  1996  4022  2000  2022  3144  1999  2796\n",
      "  4331  2349  2000  2010  6217  1998  5470  2918  2894  1012  1999  2786\n",
      "  1010 11948  5498  9126  2705  2211  4637  1996  2796  2120  3519  2044\n",
      "  3116  3539  2704  1052  1012  1058  1012 27544  5332  2213  3270 10546\n",
      "  1012  2019  5448  8554  4146  2011  1996  2932 13970 12274 17130 10173\n",
      "  2008  3519  1010  2007 11948  5498  9126  2705  1005  1055  2490  1010\n",
      "  2453  2663  2039  2000  7558  4272  1999  1996  6008 10703  3320  1012\n",
      "  1999  2727  1010  2043  1996  3519  2283  2787  2000 25705  2007  2035\n",
      "  2634  4698  2852 18891  2850 14163 10087  6494 10556 27922 16098  2213\n",
      "  1006  9932  4215  2213  2243  1007  2005  1996  3320  2602  1999  6008\n",
      " 10703  1010 11948  5498  9126  2705  2904  8884  7368  1998  3569  1996\n",
      "  2852 18891  2850 14163 10087  6494 10556 27922 16098  2213  1006  1040\n",
      "  2213  2243  1007  1011  6008  5003  7088  2721  3519  1006  1056 12458\n",
      "  1007  4707  1012  1996  1056 12458  2109  1037 10165  2004  2037  2602\n",
      "  6454  1998  2109  2019  3746  1997 11948  5498  9126  2705  5559  1037\n",
      " 10165  2013  1996  2143  4698  9067  4886  1999  2037 14921  1012 11948\n",
      "  5498  9126  2705  2056  1024  1000  2130  2643  3685  3828  6008 10703\n",
      "  2065  9932  4215  2213  2243  5651  2000  2373  1012  1000 11948  5498\n",
      "  9126  2705  2878 27693  2135  3569  1996  1040  2213  2243  1998  1056\n",
      " 12458  4707  1998  2356  1996  2111  1997  6008 10703  1998  2010  4599\n",
      "  2000  3789  2005  2008  4707  1012  2023  4707  2018  1037  3143  3377\n",
      "  1999  2727  1012 11948  5498  9126  2705  2036  3569  1996  1040  2213\n",
      "  2243  1011  1056 12458  4707  1999  1996  5768  2602  1010  2218  1996\n",
      "  2168  2095  1012  2101  1999  2432  1010 11948  5498  9126  2705  2056\n",
      "  2002  2052  7714  3789  2005  1996 24243 20308  2283  1006 24954  1007\n",
      "  2021  2052  2025  7949  2010  2490  2000  2151  2392  2076  1996  9046\n",
      "  2796  2236  2602  1012  1996  2283  1010  2174  1010  3478  2000  2663\n",
      "  2151  4272  1999  6008 10703  1999  1996 13660 11200  1012  4599  1997\n",
      " 11948  5498  9126  2705  1999  6008 10703  2031 10843 15520  2006   102]\n",
      "[  101  2339  2106  2002  2689  2010  2490  2000  2068  1029   102 17251\n",
      " 13198  2031  2036  4427  2195  4684  5097  2005 16380  1998 11924  1012\n",
      "  4401  1010  2107  2004 16480 14115 26760 24079  1010  2031  7034  2008\n",
      " 11948  5498  9126  2705  2038  1996  4022  2000  2022  3144  1999  2796\n",
      "  4331  2349  2000  2010  6217  1998  5470  2918  2894  1012  1999  2786\n",
      "  1010 11948  5498  9126  2705  2211  4637  1996  2796  2120  3519  2044\n",
      "  3116  3539  2704  1052  1012  1058  1012 27544  5332  2213  3270 10546\n",
      "  1012  2019  5448  8554  4146  2011  1996  2932 13970 12274 17130 10173\n",
      "  2008  3519  1010  2007 11948  5498  9126  2705  1005  1055  2490  1010\n",
      "  2453  2663  2039  2000  7558  4272  1999  1996  6008 10703  3320  1012\n",
      "  1999  2727  1010  2043  1996  3519  2283  2787  2000 25705  2007  2035\n",
      "  2634  4698  2852 18891  2850 14163 10087  6494 10556 27922 16098  2213\n",
      "  1006  9932  4215  2213  2243  1007  2005  1996  3320  2602  1999  6008\n",
      " 10703  1010 11948  5498  9126  2705  2904  8884  7368  1998  3569  1996\n",
      "  2852 18891  2850 14163 10087  6494 10556 27922 16098  2213  1006  1040\n",
      "  2213  2243  1007  1011  6008  5003  7088  2721  3519  1006  1056 12458\n",
      "  1007  4707  1012  1996  1056 12458  2109  1037 10165  2004  2037  2602\n",
      "  6454  1998  2109  2019  3746  1997 11948  5498  9126  2705  5559  1037\n",
      " 10165  2013  1996  2143  4698  9067  4886  1999  2037 14921  1012 11948\n",
      "  5498  9126  2705  2056  1024  1000  2130  2643  3685  3828  6008 10703\n",
      "  2065  9932  4215  2213  2243  5651  2000  2373  1012  1000 11948  5498\n",
      "  9126  2705  2878 27693  2135  3569  1996  1040  2213  2243  1998  1056\n",
      " 12458  4707  1998  2356  1996  2111  1997  6008 10703  1998  2010  4599\n",
      "  2000  3789  2005  2008  4707  1012  2023  4707  2018  1037  3143  3377\n",
      "  1999  2727  1012 11948  5498  9126  2705  2036  3569  1996  1040  2213\n",
      "  2243  1011  1056 12458  4707  1999  1996  5768  2602  1010  2218  1996\n",
      "  2168  2095  1012  2101  1999  2432  1010 11948  5498  9126  2705  2056\n",
      "  2002  2052  7714  3789  2005  1996 24243 20308  2283  1006 24954  1007\n",
      "  2021  2052  2025  7949  2010  2490  2000  2151  2392  2076  1996  9046\n",
      "  2796  2236  2602  1012  1996  2283  1010  2174  1010  3478  2000  2663\n",
      "  2151  4272  1999  6008 10703  1999  1996 13660 11200  1012  4599  1997\n",
      " 11948  5498  9126  2705  1999  6008 10703  2031 10843 15520  2006   102]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in res:\n",
    "        new = sess.run(i)\n",
    "        print(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.zeros([1,384,768])\n",
    "history_output = tf.zeros([1,12,114,768])\n",
    "history_mask = tf.zeros([12,114])\n",
    "history_turns = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num1 = history_output.shape[1]\n",
    "history_mask = tf.expand_dims(history_mask, axis=0)#1,12,114\n",
    "history_list = tf.unstack(history_output, num1, axis=1)[:history_turns]#1,114,768\n",
    "mask_list = tf.unstack(history_mask, num1, axis=1)[:history_turns]#1,114\n",
    "result = []\n",
    "for history, mask in zip(history_list, mask_list):\n",
    "    # scores: batch x word_num1 x word_num2\n",
    "    scores = scoring(input_tensor, history)#1 * 384 * 114\n",
    "    num = tf.shape(scores)[1]\n",
    "    # empty_mask = history_mask.eq(0).unsqueeze(1).expand_as(scores)\n",
    "    history_mask = tf.expand_dims(mask, 1)#1，1，114\n",
    "    empty_mask = tf.tile(history_mask, [1, num, 1])#矩阵扩张 12，12，384，114\n",
    "    score = tf.cast(scores, tf.float32)\n",
    "    empty_mask = tf.cast(empty_mask, tf.float32)\n",
    "\n",
    "    score =  (score * empty_mask)#1,384,114\n",
    "\n",
    "    # score = tf.unstack(score, axis=1)\n",
    "    # n = len(score)\n",
    "    # score = tf.concat([i for i in score], 1)\n",
    "    # softmax\n",
    "    # alpha = alpha_flat.view(-1, input_tensor.size(1), history_qa_ids.size(1))\n",
    "    alpha_flat = tf.nn.softmax(score, axis=2)\n",
    "    # alpha_flat = tf.split(alpha_flat, n, axis=1)\n",
    "    # alpha = tf.stack([i for i in alpha_flat], axis=1)\n",
    "\n",
    "    # alpha: batch x word_num1 x word_num2\n",
    "    attended = tf.matmul(alpha_flat, x3)\n",
    "    attended = tf.cast(attended, tf.float32)\n",
    "    # attended = alpha.bmm(x3)\n",
    "    # attended: batch x word_num1 x dim_3\n",
    "    result.append(attended)\n",
    "if result:\n",
    "    mean = tf.zeros(tf.shape(input_tensor), dtype=tf.float32)\n",
    "    for i in range(0, history_turns):\n",
    "        mean += result[i]\n",
    "    attend = mean / history_turns\n",
    "else:\n",
    "    attend = tf.zeros(tf.shape(input_tensor), dtype=tf.float32)\n",
    "attend = tf.squeeze(attend, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Squeeze:0' shape=(384, 768) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
